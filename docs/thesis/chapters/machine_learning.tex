\chapter{Machine Learning}

\section{Frames Sampling}
To address the variable length of segments within the dataset, in instances where we aim to attain a lower number of frames than the actual length of the segments, 
we have utilized the "uniform spacing" sampling technique to address the variability in segment lengths within the dataset.
This method entails selecting frames from a list or sequence at regular, even intervals. 
It proves to be highly advantageous when the goal is to ensure an equal distribution of frames throughout the sequence.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{graphics/subSampling.png}
    \caption{Uniform Sampling visualized}
    \label{fig:unif_sampling}
\end{figure}

Conversely, when dealing with segments that are shorter than the standard number of frames, a different technique is implemented.
In such cases, for each frame, a variable and uniform number of interpolation frames are inserted to reach the desired frame count. 
This approach compensates for the shorter segment length by adding interpolated frames, maintaining the consistency required for further analysis or processing.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.4\textwidth]{graphics/interpolationSampling.png}
    \caption{Frames interpolation visualized}
    \label{fig:interp_sampling}
\end{figure}

\section{Dataset Normalization}
As previously mentioned, our dataset consists of 60 samples, each containing the spatial positions of all 20 skeletal joints at each time step.
From the equally sampled timeseries we calculate the $x$, $y$, and $z$ coordinates of the skeleton's barycenter for each time step. \\
We define the barycenter as the point where all the mass of an object or a system of objects is concentrated. \\
In this context, each joint is considered to have unit mass, meaning that all joints contribute equally to the barycenter. \\
If we represent $n$ as the number of 20 joints, the coordinates of the barycenter are obtained by taking the average of the coordinates of these 20 joints, as we can see in the formula:


\begin{equation}
    Barycenter (x, y, z) = \left(\frac{1}{n} \sum_{i=1}^{n} x_i, \frac{1}{n} \sum_{i=1}^{n} y_i, \frac{1}{n} \sum_{i=1}^{n} z_i\right)
    \label{formula:baricentro}
\end{equation}
    
where $x_i$, $y_i$, and $z_i$ represent the $x$, $y$, and $z$ coordinates of the $i$-th joint, respectively.

Subsequently, we calculate the distance between each joint and the barycenter, at each time step, using the Euclidean distance in Formula \ref{formula:distance}. \\
These distances from the barycenter will be normalized for each joint, in order to obtain normalized time series between 0 and 1.

\begin{equation}
    x_{norm} = \frac{{x - min(x)}}{{max(x) - min(x)}}
    \label{formula:normalization}
\end{equation}
    
The choice to calculate the distances between joints and the barycenter for each sample plays a crucial role in ensuring the robustness of our ML approach to variations in scale.
In scenarios where dancers or subjects may have different heights or body proportions, relying solely on absolute joint coordinates could introduce bias into the model.
However, by computing these distances and further normalizing them within the range of 0 to 1, we effectively eliminate the influence of scale variations.

This normalization process not only standardizes the data but also allows the ML model to focus on the relative spatial distribution of joints rather than their absolute positions.
Consequently, our model becomes better equipped to recognize patterns and movements across individuals of varying statures, making it more versatile and applicable in real-world scenarios. \\

\section{Features extraction}
Feature extraction in ML is an essential process that involves transforming raw data into a more suitable format for analysis and model building.
It helps identify and capture the most relevant information within the data while simplifying excessive complexity that could make model training challenging.
This process not only contributes to improving model accuracy but also reduces the risk of overfitting and enhances the ability to generalize knowledge gained to new data. \\
From the preprocessed data, we want to extract the necessary features for ML.
Here we will see al the steps involved in order to achieve the desired features. \\


Finally, to choose the features to extract, we referred to \cite{oneto:2020} and \cite{sama:2010}.
In Table \ref{tab:ml_features} we can see all the features and their relative function.

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|}
        \hline
        \textbf{Function} & \textbf{Description} \\
        \hline
        mean & Mean Value \\
        var & Variance \\
        mad & Median Absolute Value \\
        max & Largest Value in Array \\
        min & Smallest Value in Array \\
        sma & Signal Magnitude Area \\
        energy & Average Sum of Squares \\
        iqr & Interquantile Range \\
        entropy & Signal Entropy \\
        correlation & Correlation Coefficient \\
        kurtosis & Signal Kurtosis \\
        skewness & Signal Skewness \\
        maxFreqInd & Largest Frequency Component \\
        argMaxFreqInd & Index Largest Frequency Component \\
        meanFreq & Frequency Signal Weighted Average \\
        skewnessFreq & Frequency Signal Skewness \\
        kurtosisFreq & Frequency Signal Kurtosis \\
        ampSprec & Amplitude Spectrum of the Frequency Signal \\
        angle & Phase Angle of the Frequency Signal \\
        \hline
    \end{tabular}
    \caption{List of measures for computing feature vectors}
\label{tab:ml_features}
\end{table}

\section{Method}

The initial approach to classification involves a straightforward binary classification of the origin of the movement within a specific edge.
If the results had been satisfactory, we would then have opted to evaluate progressively more complex models, eventually leading to the actual classification of the movement's origin from a video segment.

\subsection{Model creation}
We started by addressing the issue of imbalanced data in classification. Imbalanced data occurs when one class significantly outnumbers the other(s), leading to challenges in training a classifier that can effectively distinguish between the classes.
To mitigate this imbalance, a resampling technique known as B-SMOTE is employed (\textit{BS1}). The operational concept is detailed in Section \ref{subsec:borderline}.

Following the resampling of the training data, a RF classifier (\textit{RF1}) is trained on this newly balanced dataset.
To further optimize the classifier's performance, a feature selection process is employed with the goal of identifying the most influential features that contribute to accurate classification.
Initially, the most important features are determined through the training of \textit{RF1} on the resampled data. 
These crucial features are selected based on their significance in the classification task. 
Subsequently, a new RF classifier (\textit{RF2}) is trained using only the selected important features. 
To evaluate the performance of the classifier, a test set is chosen using LOOCV, as detailed in Section \ref{subsec:cross_validation}. 

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        \textbf{Model} & \textbf{Hyperparameter} & \textbf{Value} \\
        \hline
        \textit{BS1} & \textit{k}-\textit{neighbors} & 0.4 $\cdot$ count(Less Frequent Class)  \\
        & \textit{m}-\textit{neighbors} & 0.4 $\cdot$ count(Most Frequent Class)  \\
        \hline
        \textit{RF1} & \textit{n}\_\textit{estimators} & 500  \\
        & \textit{max}\_\textit{features} & Default  \\
        \hline
        \textit{RF2} & \textit{n}\_\textit{estimators} & 200  \\
        & \textit{max}\_\textit{features} & All  \\
        \hline
    \end{tabular}
    \caption{Hyperparameters tuned for our application}
    \label{tab:ml_param}
\end{table}

\subsection{Binary questions to the Model}
In our ML model, we posed three different questions regarding the OoM. 
Since our dataset is inherently a multi-class dataset, we performed binary classification by reclassifying the dataset.
These binary questions are posed either to edges or to specific parts of the skeleton, which are themselves composed of edges. \\
In Figures \ref{tab:body_division_5} and \ref{tab:top_bottom}, you can observe which edges form various parts of the skeleton. \\
Note that not every edge of the reduced marker set (\ref{tab:labels_joints}) is included because some edges have not been the ground truth for any sample in our dataset.
For ML we have in total 15 classes, that is 15 edges.

\begin{table}[H]
    \centering
    \renewcommand{\arraystretch}{0.85}
    
    \begin{subtable}{\textwidth}
        \centering
        \begin{tabular}{|c|c|}
            \hline
            \textbf{Body Part} & \textbf{Edges} \\
            \hline
            Head & shoulder\_center - head \\
            \hline
            Right Arm & right\_hand - right\_wrist \\
            & right\_wrist - right\_elbow \\
            & right\_elbow - right\_shoulder \\
            & right\_shoulder - shoulder\_center \\
            \hline
            Left Arm & left\_hand - left\_wrist \\
            & left\_elbow - left\_shoulder \\
            & left\_shoulder - shoulder\_center \\
            \hline
            Right Leg & right\_foot - right\_ankle \\
            & right\_ankle - right\_knee \\
            & right\_knee - right\_hip \\
            & right\_hip - hip\_center \\
            \hline
            Left Leg & left\_foot - left\_ankle \\
            & left\_knee - left\_hip \\
            & left\_hip - hip\_center \\
            \hline
        \end{tabular}
        \caption{}
        \label{tab:body_division_5}
    \end{subtable}

    \vspace{10pt} % Add vertical space between subtables

    \begin{subtable}{\textwidth}
        \centering
        \begin{tabular}{|c|c|}
            \hline
            \textbf{Body Part} & \textbf{Edges} \\
            \hline
            Upper & right\_hand - right\_wrist \\
            & right\_wrist - right\_elbow \\
            & right\_elbow - right\_shoulder \\
            & right\_shoulder - shoulder\_center \\
            & left\_hand - left\_wrist \\
            & left\_elbow - left\_shoulder \\
            & left\_shoulder - shoulder\_center \\
            & shoulder\_center - head \\
            \hline
            Lower & right\_foot - right\_ankle \\
            & right\_ankle - right\_knee \\
            & right\_knee - right\_hip \\
            & right\_hip - hip\_center \\
            & left\_foot - left\_ankle \\
            & left\_knee - left\_hip \\
            & left\_hip - hip\_center \\
            \hline
        \end{tabular}
        \caption{}
        \label{tab:top_bottom}
    \end{subtable}

    \caption{Skeleton Division in 5 parts (a) and in 2 parts (b)}
    \label{tab:skeleton_divisions}
\end{table}

The Q1 will be posed considering the 15 edges, the Q2 will be posed considering the division of the body into 5 parts (Figure \ref{tab:body_division_5}), while Q3 will be based on the division of the body into 2 parts (Figure \ref{tab:top_bottom}).


\begin{itemize}

    \item \textbf{(Q1) Is or is not a specific edge:} In our dataset, the most frequent classification is the edge that links \textit{left\_hand} and \textit{left\_wrist}. 
    Therefore, we categorized all samples where the classification was \textit{left\_hand}-\textit{left\_wrist} as 1, while we labeled all other samples as 0.   
    
    \item \textbf{(Q2) Is or is not a specific body part:} The most frequent class to compare against all the others is \textit{Right Leg}.
    Therefore, we labeled all samples where the classification was in the \textit{Right Leg} as 1, while we categorized all other samples as 0.

    \item \textbf{(Q3) Is or is not a specific body part:} The most frequent class between the two is \textit{Upper}, so we labeled all the $Upper$ with 1 and all the $Lower$ with 0.
    
   
\end{itemize}

For each question, we iteratively asked the model whether the test sample was predicted as that edge/that part of the body or not.

\section{Results}
In the following Tables (from \ref{table:15_confusion} to \ref{tab:2_metrics}), you will find confusion matrices and evaluation metrics for the prediction of certain classes.
To interpret the meaning of the confusion matrices, please refer to Section \ref{subsec:evaluation_metrics}.
\\

The tests to identify the best model were conducted on the most frequent edge of the dataset, \textit{left\_hand - left\_wrist} with the aim of maximize the accuracy.
This is because the dataset is unbalanced, and therefore, better prediction results are expected from this class.
As observed, accuracy consistently remains very high, almost always exceeding 70\%.
However, beyond this, the model demonstrates high specificity, meaning it excels at maximizing TN but struggles to identify TP effectively.
This inclination towards minimizing FP comes at the expense of FN.
This behavior is evident in the TPR, which varies significantly across different classes.
An emblematic example can be found in Table \ref{tab:results_edgen03}, where the TPR is 0\%.
The model requires a high level of certainty in predictions before classifying a sample as positive. \\
In summary, the model tends to favor a conservative strategy, prioritizing the reduction of FP, leading to a high specificity but limited effectiveness in identifying TP.


\begin{table}[H]
    \centering
    \renewcommand{\arraystretch}{1.6} % Aumenta lo spazio tra le righe del doppio
    \begin{subfigure}[b]{0.1\textwidth}
        \centering
        \begin{tabular}{|>{\centering\arraybackslash}p{0.5cm}|>{\centering\arraybackslash}p{0.5cm}|}
        \hline
        48 & 3 \\
        \hline
        3 & 6 \\
        \hline
        \end{tabular}
        \caption{}
        \label{tab:results_edgen01}
    \end{subfigure}
    \hspace{0.05\linewidth}
    \begin{subfigure}[b]{0.1\textwidth}
        \centering
        \begin{tabular}{|>{\centering\arraybackslash}p{0.5cm}|>{\centering\arraybackslash}p{0.5cm}|}
        \hline
        51 & 2 \\
        \hline
        6 & 1 \\
        \hline
        \end{tabular}
        \caption{}
        \label{tab:results_edgen02}
    \end{subfigure}
    \hspace{0.05\linewidth}
    \begin{subfigure}[b]{0.1\textwidth}
        \centering
        \begin{tabular}{|>{\centering\arraybackslash}p{0.5cm}|>{\centering\arraybackslash}p{0.5cm}|}
        \hline
        44 & 9 \\
        \hline
        7 & 0 \\
        \hline
        \end{tabular}
        \caption{}
        \label{tab:results_edgen03}
    \end{subfigure}
    \hspace{0.05\linewidth}
    \begin{subfigure}[b]{0.1\textwidth}
        \centering
        \begin{tabular}{|>{\centering\arraybackslash}p{0.5cm}|>{\centering\arraybackslash}p{0.5cm}|}
        \hline
        51 & 3 \\
        \hline
        4 & 2\\
        \hline
        \end{tabular}
        \caption{}
        \label{tab:results_edgen04}
    \end{subfigure}
    \hspace{0.05\linewidth}
    \begin{subfigure}[b]{0.1\textwidth}
        \centering
        \begin{tabular}{|>{\centering\arraybackslash}p{0.5cm}|>{\centering\arraybackslash}p{0.5cm}|}
        \hline
        52 & 3 \\
        \hline
        4 & 1 \\
        \hline
        \end{tabular}
        \caption{}
        \label{tab:results_edgen05}
    \end{subfigure}
    \hspace{0.05\linewidth}
    \begin{subfigure}[b]{0.1\textwidth}
        \centering
        \begin{tabular}{|>{\centering\arraybackslash}p{0.5cm}|>{\centering\arraybackslash}p{0.5cm}|}
        \hline
        53 & 2 \\
        \hline
        2 & 3 \\
        \hline
        \end{tabular}
        \caption{}
        \label{tab:results_edgen06}
    \end{subfigure}
    \hspace{0.05\linewidth}
    \caption{Confusion matrices of the 6 most frequent classes in the dataset}
    \label{table:15_confusion}
\end{table}

TODO AGGIUNGERE TOP FEATURES PER EXPLAINABILITY


\begin{table}[H]
    \centering
    \begin{tabular}{|>{\centering\arraybackslash}p{2cm}|>{\centering\arraybackslash}p{6cm}|>{\centering\arraybackslash}p{2cm}|>{\centering\arraybackslash}p{2cm}|}
    \hline
    \textbf{Label} & \textbf{Edge} & \textbf{TPR} & \textbf{Accuracy} \\
    \hline
    (a) & left\_hand - left\_wrist  & 66\% & 90\% \\
    \hline
    (b) & shoulder\_center - head  & 14\% & 87\% \\
    \hline
    (c) & right\_elbow - right\_shoulder  & 0\%  & 73\% \\ 
    \hline
    (d) & right\_shoulder - shoulder\_center & 33\% & 88\% \\
    \hline
    (e) & right\_knee - right\_hip  & 20\%  & 88\%\\
    \hline
    (f) & left\_knee - left\_hip  & 60\% & 93\%\\ 
    \hline
    \end{tabular}
    \caption{Metrics of the 6 classes most frequent of the dataset}
    \label{tab:15_metrics}
\end{table}




\begin{table}[H]
  \begin{minipage}[b]{0.17\textwidth}
    \centering
    \renewcommand{\arraystretch}{1.6} % Aumenta lo spazio tra le righe del doppio
    \begin{tabular}{|>{\centering\arraybackslash}p{0.5cm}|>{\centering\arraybackslash}p{0.5cm}|}
    \hline
    37 & 5 \\
    \hline
    7 & 11 \\
    \hline
    \end{tabular}
    \caption*{(g)}
    \label{tab:perm1}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.17\textwidth}
    \centering
    \renewcommand{\arraystretch}{1.6} % Aumenta lo spazio tra le righe del doppio
    \begin{tabular}{|>{\centering\arraybackslash}p{0.5cm}|>{\centering\arraybackslash}p{0.5cm}|}
    \hline
    37 & 9 \\
    \hline
    10 & 4 \\
    \hline
    \end{tabular}
    \caption*{(h)}
    \label{tab:perm2}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.17\textwidth}
    \centering
    \renewcommand{\arraystretch}{1.6} % Aumenta lo spazio tra le righe del doppio
    \begin{tabular}{|>{\centering\arraybackslash}p{0.5cm}|>{\centering\arraybackslash}p{0.5cm}|}
    \hline
    43 & 4 \\
    \hline
    6 & 7 \\
    \hline
    \end{tabular}
    \caption*{(i)}
    \label{tab:perm3}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.17\textwidth}
    \centering
    \renewcommand{\arraystretch}{1.6} % Aumenta lo spazio tra le righe del doppio
    \begin{tabular}{|>{\centering\arraybackslash}p{0.5cm}|>{\centering\arraybackslash}p{0.5cm}|}
    \hline
    47 & 5 \\
    \hline
    7 & 1\\
    \hline
    \end{tabular}
    \caption*{(l)}
    \label{tab:perm3}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.17\textwidth}
    \centering
    \renewcommand{\arraystretch}{1.6} % Aumenta lo spazio tra le righe del doppio
    \begin{tabular}{|>{\centering\arraybackslash}p{0.5cm}|>{\centering\arraybackslash}p{0.5cm}|}
    \hline
    51 & 2 \\
    \hline
    6 & 1 \\
    \hline
    \end{tabular}
    \caption*{(m)}
    \label{tab:perm3}
  \end{minipage}
  \hfill
  \caption{Confusion matrices of the 5 Body Parts}
  \label{table:5_confusion}
\end{table}


\begin{table}[H]
    \centering
    \begin{tabular}{|>{\centering\arraybackslash}p{2cm}|>{\centering\arraybackslash}p{6cm}|>{\centering\arraybackslash}p{2cm}|>{\centering\arraybackslash}p{2cm}|}
        \hline
        \textbf{Label} & \textbf{Body Part} & \textbf{TPR} & \textbf{Accuracy} \\
        \hline
        (g) & Right Arm  & 61\% & 80\% \\
        \hline
        (h) & Left Arm & 29\% & 68\% \\
        \hline
        (i) & Right Leg  & 54\%  & 83\% \\ 
        \hline
        (l) & Left Leg & 12\% & 80\% \\
        \hline
        (m) & Head  & 14\%  & 86\%\\
        \hline
    \end{tabular}
    \caption{Metrics of the 5 Body Parts}
    \label{tab:5_metrics}
\end{table}


\begin{table}[H]
    \centering
    \renewcommand{\arraystretch}{1.6} % Aumenta lo spazio tra le righe del doppio
    \begin{tabular}{|>{\centering\arraybackslash}p{0.5cm}|>{\centering\arraybackslash}p{0.5cm}|}
    \hline
    16 & 5 \\
    \hline
    8 & 31 \\
    \hline
    \end{tabular}
    \caption{Confusion matrix of the 2 Body Parts}
    \label{table:2_confusion}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|>{\centering\arraybackslash}p{2cm}|>{\centering\arraybackslash}p{6cm}|>{\centering\arraybackslash}p{2cm}|>{\centering\arraybackslash}p{2cm}|}
        \hline
        \textbf{Label} & \textbf{Body Part} & \textbf{TPR} & \textbf{Accuracy} \\
        \hline
        (n) & Upper & 79\% & 78\% \\
        \hline
    \end{tabular}
    \caption{Metrics of the 2 Body Parts}
    \label{tab:2_metrics}
\end{table}
