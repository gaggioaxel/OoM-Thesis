{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries installation on the current python environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%reset -f\n",
    "try:\n",
    "    import networkx \n",
    "except:\n",
    "    %pip install networkx==3.1\n",
    "    %pip install numpy==1.23.5\n",
    "    %pip install pandas==2.0.3\n",
    "    %pip install pillow==10.0.0\n",
    "    %pip install scikit-learn==1.3.0\n",
    "    %pip install scipy==1.11\n",
    "    %pip install matplotlib==3.7.1\n",
    "    %pip isntall matplotlib-inline==0.1.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def custom_header_reader(file:'TextIOWrapper'):\n",
    "    csvReader = csv.reader(file,delimiter='\\t')\n",
    "    for row, text in enumerate(csvReader):\n",
    "        if row == 2: numMarkers = int(text[-1])\n",
    "        elif row == 10: \n",
    "            columnNames = text[:-1]\n",
    "            if columnNames[0] == 'Frame': \n",
    "                break\n",
    "        elif row == 11: columnNames = text[:-1]; break\n",
    "    return numMarkers, columnNames, csvReader\n",
    "\n",
    "def line_reader(csvReader,fromSecond,toSecond):\n",
    "    for line in csvReader:\n",
    "        if fromSecond <= float(line[1]) <= toSecond:\n",
    "            yield line[:len(columnNames)]\n",
    "        elif float(line[1]) > toSecond:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleAnno = 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "data/raw/2016-05-27/t_001.tsv 56.1 56.8\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/gagg/Desktop/Thesis/OoM-Thesis/code/src/OoM.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gagg/Desktop/Thesis/OoM-Thesis/code/src/OoM.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     numMarkers, columnNames, readerBuffer \u001b[39m=\u001b[39m custom_header_reader(file)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gagg/Desktop/Thesis/OoM-Thesis/code/src/OoM.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(line_reader(readerBuffer,\u001b[39mfloat\u001b[39m(startSec),\u001b[39mfloat\u001b[39m(endSec)),columns\u001b[39m=\u001b[39mcolumnNames)\u001b[39m.\u001b[39mastype(\u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(columnNames,[\u001b[39mint\u001b[39m,\u001b[39mfloat\u001b[39m,\u001b[39mstr\u001b[39m]\u001b[39m+\u001b[39m[\u001b[39mfloat\u001b[39m]\u001b[39m*\u001b[39m\u001b[39mlen\u001b[39m(columnNames[\u001b[39m3\u001b[39m:]))))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/gagg/Desktop/Thesis/OoM-Thesis/code/src/OoM.ipynb#X10sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mif\u001b[39;00m data[\u001b[39m'\u001b[39;49m\u001b[39mTime\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49miloc[\u001b[39m0\u001b[39;49m] \u001b[39m>\u001b[39m \u001b[39mfloat\u001b[39m(startSec) \u001b[39mor\u001b[39;00m data[\u001b[39m'\u001b[39m\u001b[39mTime\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39miloc[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m<\u001b[39m \u001b[39mfloat\u001b[39m(endSec):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gagg/Desktop/Thesis/OoM-Thesis/code/src/OoM.ipynb#X10sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\x1b\u001b[39;00m\u001b[39m[31mNOT FULL FRAMES!!! data starts at: \u001b[39m\u001b[39m{\u001b[39;00mdata[\u001b[39m\"\u001b[39m\u001b[39mTime\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mfloat\u001b[39m(startSec)\u001b[39m}\u001b[39;00m\u001b[39m and ends at \u001b[39m\u001b[39m{\u001b[39;00mdata[\u001b[39m\"\u001b[39m\u001b[39mTime\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39miloc[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mfloat\u001b[39m(endSec)\u001b[39m}\u001b[39;00m\u001b[39m\\x1b\u001b[39;00m\u001b[39m[0m\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gagg/Desktop/Thesis/OoM-Thesis/code/src/OoM.ipynb#X10sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/pandas/core/indexing.py:1103\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1100\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m   1102\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[0;32m-> 1103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/pandas/core/indexing.py:1656\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1653\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index by location index with a non-integer key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1655\u001b[0m \u001b[39m# validate the location\u001b[39;00m\n\u001b[0;32m-> 1656\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_integer(key, axis)\n\u001b[1;32m   1658\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_ixs(key, axis\u001b[39m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/pandas/core/indexing.py:1589\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1587\u001b[0m len_axis \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis))\n\u001b[1;32m   1588\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m len_axis \u001b[39mor\u001b[39;00m key \u001b[39m<\u001b[39m \u001b[39m-\u001b[39mlen_axis:\n\u001b[0;32m-> 1589\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msingle positional indexer is out-of-bounds\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "ANNOTATIONS_PATH = 'data'\n",
    "RAW_PATH = ANNOTATIONS_PATH+'/raw'\n",
    "#with open(ANNOTATIONS_PATH+'/annotations.txt','r') as file:\n",
    "#    annotations = file.read().splitlines()\n",
    "with open(ANNOTATIONS_PATH+'/annotationsVReduced.txt','r') as file:\n",
    "    annotations = file.read().splitlines()[1:]#[line for line in file.read().splitlines() if 'no val' in line]\n",
    "    print(len(annotations))\n",
    "\n",
    "if '(A)' in annotations[sampleAnno] or '(B)' in annotations[sampleAnno]:\n",
    "    folder, trial, fragId, side, OoM, startSec, endSec = annotations[sampleAnno].replace(' ','').split(',')[:7]\n",
    "else:\n",
    "    folder, trial, fragId, OoM, startSec, endSec = annotations[sampleAnno].replace(' ','').split(',')[:6]\n",
    "sampleData = os.path.join(RAW_PATH,folder,trial+'.tsv')\n",
    "print(sampleData,startSec,endSec)\n",
    "with open(sampleData,'r') as file:\n",
    "    numMarkers, columnNames, readerBuffer = custom_header_reader(file)\n",
    "    data = pd.DataFrame(line_reader(readerBuffer,float(startSec),float(endSec)),columns=columnNames).astype(dict(zip(columnNames,[int,float,str]+[float]*len(columnNames[3:]))))\n",
    "if data['Time'].iloc[0] > float(startSec) or data['Time'].iloc[-1] < float(endSec):\n",
    "    raise Exception(f'\\x1b[31mNOT FULL FRAMES!!! data starts at: {data[\"Time\"].iloc[0]} of {float(startSec)} and ends at {data[\"Time\"].iloc[-1]} of {float(endSec)}\\x1b[0m')\n",
    "else:\n",
    "    print(\"\\x1b[32mSTART AND END SECONDS CHECK CORRECT!\\x1b[0m\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARIEL X</th>\n",
       "      <th>LFHD X</th>\n",
       "      <th>RFHD X</th>\n",
       "      <th>C7 X</th>\n",
       "      <th>T5 X</th>\n",
       "      <th>T10 X</th>\n",
       "      <th>BWT X</th>\n",
       "      <th>FWT X</th>\n",
       "      <th>STRN X</th>\n",
       "      <th>LBSH X</th>\n",
       "      <th>...</th>\n",
       "      <th>RPNKY X</th>\n",
       "      <th>LTHMB X</th>\n",
       "      <th>LINDX X</th>\n",
       "      <th>LPNKY X</th>\n",
       "      <th>LFRM X</th>\n",
       "      <th>LFSH X</th>\n",
       "      <th>RBHD X</th>\n",
       "      <th>LBHD X</th>\n",
       "      <th>RPLM X</th>\n",
       "      <th>LPLM X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-123.375</td>\n",
       "      <td>-200.914</td>\n",
       "      <td>-195.869</td>\n",
       "      <td>104.850</td>\n",
       "      <td>305.397</td>\n",
       "      <td>458.390</td>\n",
       "      <td>549.711</td>\n",
       "      <td>279.138</td>\n",
       "      <td>115.511</td>\n",
       "      <td>255.077</td>\n",
       "      <td>...</td>\n",
       "      <td>-518.325</td>\n",
       "      <td>15.337</td>\n",
       "      <td>-24.642</td>\n",
       "      <td>18.882</td>\n",
       "      <td>283.354</td>\n",
       "      <td>88.939</td>\n",
       "      <td>-14.338</td>\n",
       "      <td>-36.198</td>\n",
       "      <td>-462.023</td>\n",
       "      <td>85.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-124.203</td>\n",
       "      <td>-201.810</td>\n",
       "      <td>-196.825</td>\n",
       "      <td>103.596</td>\n",
       "      <td>304.319</td>\n",
       "      <td>457.864</td>\n",
       "      <td>549.682</td>\n",
       "      <td>279.189</td>\n",
       "      <td>115.345</td>\n",
       "      <td>253.919</td>\n",
       "      <td>...</td>\n",
       "      <td>-519.094</td>\n",
       "      <td>16.403</td>\n",
       "      <td>-23.038</td>\n",
       "      <td>20.563</td>\n",
       "      <td>283.471</td>\n",
       "      <td>88.285</td>\n",
       "      <td>-15.149</td>\n",
       "      <td>-37.043</td>\n",
       "      <td>-462.915</td>\n",
       "      <td>86.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-125.030</td>\n",
       "      <td>-202.472</td>\n",
       "      <td>-197.454</td>\n",
       "      <td>102.216</td>\n",
       "      <td>303.158</td>\n",
       "      <td>457.539</td>\n",
       "      <td>549.724</td>\n",
       "      <td>279.389</td>\n",
       "      <td>115.084</td>\n",
       "      <td>252.701</td>\n",
       "      <td>...</td>\n",
       "      <td>-519.891</td>\n",
       "      <td>17.481</td>\n",
       "      <td>-21.576</td>\n",
       "      <td>22.346</td>\n",
       "      <td>283.569</td>\n",
       "      <td>87.648</td>\n",
       "      <td>-16.262</td>\n",
       "      <td>-37.962</td>\n",
       "      <td>-463.655</td>\n",
       "      <td>88.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-125.919</td>\n",
       "      <td>-203.645</td>\n",
       "      <td>-198.780</td>\n",
       "      <td>100.904</td>\n",
       "      <td>302.109</td>\n",
       "      <td>457.026</td>\n",
       "      <td>549.922</td>\n",
       "      <td>279.717</td>\n",
       "      <td>114.855</td>\n",
       "      <td>251.349</td>\n",
       "      <td>...</td>\n",
       "      <td>-520.460</td>\n",
       "      <td>18.346</td>\n",
       "      <td>-20.004</td>\n",
       "      <td>24.209</td>\n",
       "      <td>283.559</td>\n",
       "      <td>87.322</td>\n",
       "      <td>-17.214</td>\n",
       "      <td>-38.981</td>\n",
       "      <td>-464.313</td>\n",
       "      <td>90.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-126.934</td>\n",
       "      <td>-204.738</td>\n",
       "      <td>-199.868</td>\n",
       "      <td>99.429</td>\n",
       "      <td>300.849</td>\n",
       "      <td>456.537</td>\n",
       "      <td>550.368</td>\n",
       "      <td>280.061</td>\n",
       "      <td>114.984</td>\n",
       "      <td>250.104</td>\n",
       "      <td>...</td>\n",
       "      <td>-521.042</td>\n",
       "      <td>19.376</td>\n",
       "      <td>-18.329</td>\n",
       "      <td>26.117</td>\n",
       "      <td>283.345</td>\n",
       "      <td>86.767</td>\n",
       "      <td>-18.180</td>\n",
       "      <td>-40.046</td>\n",
       "      <td>-464.882</td>\n",
       "      <td>91.846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ARIEL X   LFHD X   RFHD X     C7 X     T5 X    T10 X    BWT X    FWT X  \\\n",
       "0 -123.375 -200.914 -195.869  104.850  305.397  458.390  549.711  279.138   \n",
       "1 -124.203 -201.810 -196.825  103.596  304.319  457.864  549.682  279.189   \n",
       "2 -125.030 -202.472 -197.454  102.216  303.158  457.539  549.724  279.389   \n",
       "3 -125.919 -203.645 -198.780  100.904  302.109  457.026  549.922  279.717   \n",
       "4 -126.934 -204.738 -199.868   99.429  300.849  456.537  550.368  280.061   \n",
       "\n",
       "    STRN X   LBSH X  ...  RPNKY X  LTHMB X  LINDX X  LPNKY X   LFRM X  LFSH X  \\\n",
       "0  115.511  255.077  ... -518.325   15.337  -24.642   18.882  283.354  88.939   \n",
       "1  115.345  253.919  ... -519.094   16.403  -23.038   20.563  283.471  88.285   \n",
       "2  115.084  252.701  ... -519.891   17.481  -21.576   22.346  283.569  87.648   \n",
       "3  114.855  251.349  ... -520.460   18.346  -20.004   24.209  283.559  87.322   \n",
       "4  114.984  250.104  ... -521.042   19.376  -18.329   26.117  283.345  86.767   \n",
       "\n",
       "   RBHD X  LBHD X   RPLM X  LPLM X  \n",
       "0 -14.338 -36.198 -462.023  85.158  \n",
       "1 -15.149 -37.043 -462.915  86.732  \n",
       "2 -16.262 -37.962 -463.655  88.406  \n",
       "3 -17.214 -38.981 -464.313  90.106  \n",
       "4 -18.180 -40.046 -464.882  91.846  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 952,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data))\n",
    "data.iloc[:,3::3].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ARIEL',\n",
       " 'LFHD',\n",
       " 'RFHD',\n",
       " 'C7',\n",
       " 'T5',\n",
       " 'T10',\n",
       " 'BWT',\n",
       " 'FWT',\n",
       " 'STRN',\n",
       " 'LBSH',\n",
       " 'LSHO',\n",
       " 'LFUPA',\n",
       " 'LBUPA',\n",
       " 'LIEL',\n",
       " 'LELB',\n",
       " 'LOWR',\n",
       " 'LIWR',\n",
       " 'RSHO',\n",
       " 'RBSH',\n",
       " 'RFUPA',\n",
       " 'RBUPA',\n",
       " 'RFSH',\n",
       " 'RIEL',\n",
       " 'RELB',\n",
       " 'RFRM',\n",
       " 'ROWR',\n",
       " 'RIWR',\n",
       " 'LBWT',\n",
       " 'RBWT',\n",
       " 'LBTHI',\n",
       " 'LKNE',\n",
       " 'LKNI',\n",
       " 'LSHN',\n",
       " 'LANK',\n",
       " 'LHEL',\n",
       " 'LTOE',\n",
       " 'LMT1',\n",
       " 'LMT5',\n",
       " 'RBTHI',\n",
       " 'RKNE',\n",
       " 'RKNI',\n",
       " 'RSHN',\n",
       " 'RANK',\n",
       " 'RHEL',\n",
       " 'RTOE',\n",
       " 'RMT1',\n",
       " 'RMT5',\n",
       " 'RTHMB',\n",
       " 'RINDX',\n",
       " 'RPNKY',\n",
       " 'LTHMB',\n",
       " 'LINDX',\n",
       " 'LPNKY',\n",
       " 'LFRM',\n",
       " 'LFSH',\n",
       " 'RBHD',\n",
       " 'LBHD',\n",
       " 'RPLM',\n",
       " 'LPLM']"
      ]
     },
     "execution_count": 953,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[colname[:-2] for colname in list(data.iloc[:1,3::3].columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "if '_A' in data.columns[3] or '_B' in data.columns[3]:\n",
    "    data = data[['Frame','Time','SMPTE']+data.filter(like=f'_{side[1]}').columns.tolist()]\n",
    "    data.columns = [col.replace(f'_{side[1]}','') for col in data.columns]\n",
    "elif '61A' in data.columns[3] or '61B' in data.columns[3]:\n",
    "    data = data[['Frame','Time','SMPTE']+data.filter(like=f'61{side[1]}').columns.tolist()]\n",
    "    data.columns = [col.replace(f'61{side[1]}_','') for col in data.columns]\n",
    "if '_01' in data.columns[3]:\n",
    "    data.columns = [column for column in data.columns[:3]]+[column[:-5]+column[-2:] for column in data.columns[3:]]\n",
    "if 'HeadFront' in data.columns[3] or 'RKneeIn' in data.columns[3]:\n",
    "    mappings = pd.read_csv(\"data/raw/ExtendedMarkersToStandard.csv\")\n",
    "    mappings = mappings.set_index(mappings.columns[0])[mappings.columns[1]].to_dict()\n",
    "    data.columns = [mappings[col[:-2]]+col[-2:] if col[:-2] in mappings.keys() else col for col in data.columns]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Frame',\n",
       " 'Time',\n",
       " 'SMPTE',\n",
       " 'ARIEL X',\n",
       " 'LFHD X',\n",
       " 'RFHD X',\n",
       " 'C7 X',\n",
       " 'T5 X',\n",
       " 'T10 X',\n",
       " 'BWT X',\n",
       " 'FWT X',\n",
       " 'STRN X',\n",
       " 'LBSH X',\n",
       " 'LSHO X',\n",
       " 'LFUPA X',\n",
       " 'LBUPA X',\n",
       " 'LIEL X',\n",
       " 'LELB X',\n",
       " 'LOWR X',\n",
       " 'LIWR X',\n",
       " 'RSHO X',\n",
       " 'RBSH X',\n",
       " 'RFUPA X',\n",
       " 'RBUPA X',\n",
       " 'RFSH X',\n",
       " 'RIEL X',\n",
       " 'RELB X',\n",
       " 'RFRM X',\n",
       " 'ROWR X',\n",
       " 'RIWR X',\n",
       " 'LBWT X',\n",
       " 'RBWT X',\n",
       " 'LBTHI X',\n",
       " 'LKNE X',\n",
       " 'LKNI X',\n",
       " 'LSHN X',\n",
       " 'LANK X',\n",
       " 'LHEL X',\n",
       " 'LTOE X',\n",
       " 'LMT1 X',\n",
       " 'LMT5 X',\n",
       " 'RBTHI X',\n",
       " 'RKNE X',\n",
       " 'RKNI X',\n",
       " 'RSHN X',\n",
       " 'RANK X',\n",
       " 'RHEL X',\n",
       " 'RTOE X',\n",
       " 'RMT1 X',\n",
       " 'RMT5 X',\n",
       " 'RTHMB X',\n",
       " 'RINDX X',\n",
       " 'RPNKY X',\n",
       " 'LTHMB X',\n",
       " 'LINDX X',\n",
       " 'LPNKY X',\n",
       " 'LFRM X',\n",
       " 'LFSH X',\n",
       " 'RBHD X',\n",
       " 'LBHD X',\n",
       " 'RPLM X',\n",
       " 'LPLM X']"
      ]
     },
     "execution_count": 955,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.columns)[:3]+list(data.columns)[3::3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total NaNs\n",
      "\u001b[32mSeries([], dtype: float64)\u001b[0m \n",
      "No Nans\n"
     ]
    }
   ],
   "source": [
    "print(\"Total NaNs\")\n",
    "nans = data[data.columns[(data.isna().sum(axis=0) > 0 ).to_list()]].isna().sum(axis=0).sort_values(ascending=False)\n",
    "color = '\\x1b[32m' if len(nans) == 0 else '\\x1b[31m'\n",
    "print(color+str(nans)+'\\x1b[0m '+ ('\\nNo Nans' if len(nans)==0 else '\\nNans found!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max contiguous NaNs\n",
      "\u001b[32mSeries([], dtype: int64)\u001b[0m \n",
      "No Nans\n"
     ]
    }
   ],
   "source": [
    "from itertools import groupby\n",
    "max_nans_per_column = data.apply(lambda col: max(len(list(group))*value for value, group in groupby(col.isna().tolist())))\n",
    "print(\"Max contiguous NaNs\")\n",
    "max_nans_per_column = max_nans_per_column[max_nans_per_column > 0].sort_values(ascending=False)\n",
    "color = '\\x1b[32m' if len(max_nans_per_column) == 0 else '\\x1b[31m'\n",
    "print(color+str(max_nans_per_column)+'\\x1b[0m ' + ('\\nNo Nans' if len(nans)==0 else '\\nNans found!'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Zeros\n",
      "\u001b[32mSeries([], dtype: float64)\u001b[0m \n",
      "No Zeros\n"
     ]
    }
   ],
   "source": [
    "print('Num Zeros')\n",
    "zeros = data[data.columns[(data.eq(0.0).sum(axis=0) > 0).to_list()]].eq(0.0).sum(axis=0).sort_values(ascending=False)\n",
    "color = '\\x1b[32m' if len(zeros) == 0 else '\\x1b[31m'\n",
    "print(color+str(zeros)+'\\x1b[0m ' + ('\\nNo Zeros' if len(zeros)==0 else '\\nZeros found!'))\n",
    "#list(zeros.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS A FIX FOR MISSING QTM AT DATA 58-59\n",
    "import numpy as np\n",
    "if len(zeros.index) > 15:\n",
    "    for name_col,num_zeros in zeros.items():\n",
    "        if num_zeros < 50:\n",
    "            data[name_col] = data[name_col].replace(0.0,np.nan).interpolate(method='spline', order=3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max contiguous Zeros\n",
      "\u001b[32mSeries([], dtype: int64)\u001b[0m \n",
      "No Zeros\n"
     ]
    }
   ],
   "source": [
    "from itertools import groupby\n",
    "max_zeros_per_column = data.apply(lambda col: max(len(list(group))*value for value, group in groupby(col.eq(0.0).tolist())))\n",
    "print(\"Max contiguous Zeros\")\n",
    "max_zeros_per_column = max_zeros_per_column[max_zeros_per_column > 0].sort_values(ascending=False)\n",
    "color = '\\x1b[32m' if len(max_zeros_per_column) == 0 else '\\x1b[31m'\n",
    "print(color+str(max_zeros_per_column)+'\\x1b[0m ' + ('\\nNo Zeros' if len(max_zeros_per_column)==0 else '\\nZeros found!'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to reduced marker set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fullbodymarkers](../resources/fullmarkerset.png) ![markerstable](../resources/markersetable.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_reduce_num_markers(reducedMarkerNames:list):\n",
    "    markersMap = {reducedMarkerNames[0]:   ['LHEL','LMT1','LMT5','LTOE'],\n",
    "                  reducedMarkerNames[1]:   ['RHEL','RMT1','RMT5','RTOE'],\n",
    "                  reducedMarkerNames[2]:   ['LANK'],\n",
    "                  reducedMarkerNames[3]:   ['RANK'],\n",
    "                  reducedMarkerNames[4]:   ['LKNE','LKNI'],\n",
    "                  reducedMarkerNames[5]:   ['RKNE','RKNI'],\n",
    "                  reducedMarkerNames[6]:   ['LFWT','LBWT'],\n",
    "                  reducedMarkerNames[7]:   ['RFWT','LFWT','RBWT','LBWT'],\n",
    "                  reducedMarkerNames[8]:   ['RFWT','RBWT'],\n",
    "                  reducedMarkerNames[9]:   ['C6','C7','T5','T10','BWT','STRN','CLAV','FWT'],\n",
    "                  reducedMarkerNames[10]:  ['LPLM','LTHMB','LINDX','LMID','LPNKY'],\n",
    "                  reducedMarkerNames[11]:  ['RPLM','RTHMB','RINDX','RMID','RPNKY'],\n",
    "                  reducedMarkerNames[12]:  ['LOWR','LIWR'],\n",
    "                  reducedMarkerNames[13]:  ['ROWR','RIWR'],\n",
    "                  reducedMarkerNames[14]:  ['LELB','LIEL','LFRM'],\n",
    "                  reducedMarkerNames[15]:  ['RELB','RIEL','RFRM'],\n",
    "                  reducedMarkerNames[16]:  ['LSHO'],\n",
    "                  reducedMarkerNames[17]:  ['RSHO','LSHO'],\n",
    "                  reducedMarkerNames[18]:  ['RSHO'],\n",
    "                  reducedMarkerNames[19]:  ['ARIEL','RFHD','LFHD','RBHD','LBHD']\n",
    "                  }\n",
    "    #   removing nan joints\n",
    "    for nan_joint_name,_ in max_nans_per_column[::3].items():\n",
    "        nan_joint_name = nan_joint_name[:-2]\n",
    "        for markerFullList in markersMap.values():\n",
    "            if nan_joint_name in markerFullList:\n",
    "                markerFullList.remove(nan_joint_name)\n",
    "                break\n",
    "    # removing many contiguous zeros joints\n",
    "    for zero_joint_name,contiguous_zeros in max_zeros_per_column[::3].items():\n",
    "        if contiguous_zeros > 20:\n",
    "            zero_joint_name = zero_joint_name[:-2]\n",
    "            for markerFullList in markersMap.values():\n",
    "                if zero_joint_name in markerFullList:\n",
    "                    markerFullList.remove(zero_joint_name)\n",
    "                    break\n",
    "    originalDataColumns = [colname[:-2] for colname in list(data.iloc[:1,3::3].columns)]\n",
    "    \n",
    "    #   removing markers not present in the data markers\n",
    "    for markerFullList in markersMap.values():\n",
    "        for markerName in list(reversed(markerFullList)):\n",
    "            if not markerName in originalDataColumns:\n",
    "                markerFullList.remove(markerName)\n",
    "\n",
    "    #   removing asymmetries across body\n",
    "    for left_side_marker_indx,right_side_marker_indx in [(0,1),(4,5),(6,8),(10,11),(12,13),(14,15)]: # indices of every marker on the left side and his symmetric\n",
    "        markersLeft = markersMap[reducedMarkerNames[left_side_marker_indx]]\n",
    "        markersRight = markersMap[reducedMarkerNames[right_side_marker_indx]]\n",
    "        for elem in markersLeft:\n",
    "            if not 'R'+elem[1:] in markersRight:\n",
    "                markersLeft.remove(elem)\n",
    "                if left_side_marker_indx == 6: \n",
    "                    markersMap[reducedMarkerNames[7]].remove(elem)\n",
    "        for elem in markersRight:\n",
    "            if not 'L'+elem[1:] in markersLeft:\n",
    "                markersRight.remove(elem)\n",
    "                if left_side_marker_indx == 6: \n",
    "                    markersMap[reducedMarkerNames[7]].remove(elem)\n",
    "\n",
    "    for i,markerFullList in enumerate(markersMap.values()):\n",
    "        if len(markerFullList) == 0:\n",
    "            print(markersMap)\n",
    "            raise Exception(f\"can't reconstruct '{reducedMarkerNames[i]}' of 20 markers, because every marker of the full set is missing!!\")\n",
    "    return markersMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_foot_X</th>\n",
       "      <th>left_foot_Y</th>\n",
       "      <th>left_foot_Z</th>\n",
       "      <th>right_foot_X</th>\n",
       "      <th>right_foot_Y</th>\n",
       "      <th>right_foot_Z</th>\n",
       "      <th>left_ank_X</th>\n",
       "      <th>left_ank_Y</th>\n",
       "      <th>left_ank_Z</th>\n",
       "      <th>right_ank_X</th>\n",
       "      <th>...</th>\n",
       "      <th>left_shoulder_Z</th>\n",
       "      <th>shoulder_center_X</th>\n",
       "      <th>shoulder_center_Y</th>\n",
       "      <th>shoulder_center_Z</th>\n",
       "      <th>right_shoulder_X</th>\n",
       "      <th>right_shoulder_Y</th>\n",
       "      <th>right_shoulder_Z</th>\n",
       "      <th>head_X</th>\n",
       "      <th>head_Y</th>\n",
       "      <th>head_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.460614</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.485203</td>\n",
       "      <td>0.443349</td>\n",
       "      <td>0.005469</td>\n",
       "      <td>0.260588</td>\n",
       "      <td>0.511488</td>\n",
       "      <td>0.020407</td>\n",
       "      <td>0.492017</td>\n",
       "      <td>0.490406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.491060</td>\n",
       "      <td>0.507807</td>\n",
       "      <td>0.875500</td>\n",
       "      <td>0.406681</td>\n",
       "      <td>0.472630</td>\n",
       "      <td>0.837056</td>\n",
       "      <td>0.322301</td>\n",
       "      <td>0.561631</td>\n",
       "      <td>0.929868</td>\n",
       "      <td>0.303745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.460578</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.485146</td>\n",
       "      <td>0.443353</td>\n",
       "      <td>0.005227</td>\n",
       "      <td>0.260808</td>\n",
       "      <td>0.511440</td>\n",
       "      <td>0.020438</td>\n",
       "      <td>0.491954</td>\n",
       "      <td>0.490729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.490244</td>\n",
       "      <td>0.507147</td>\n",
       "      <td>0.871966</td>\n",
       "      <td>0.405486</td>\n",
       "      <td>0.470012</td>\n",
       "      <td>0.832011</td>\n",
       "      <td>0.320728</td>\n",
       "      <td>0.562917</td>\n",
       "      <td>0.929760</td>\n",
       "      <td>0.303000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.460574</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.485081</td>\n",
       "      <td>0.443325</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.511433</td>\n",
       "      <td>0.020473</td>\n",
       "      <td>0.491871</td>\n",
       "      <td>0.491071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.489521</td>\n",
       "      <td>0.506239</td>\n",
       "      <td>0.868436</td>\n",
       "      <td>0.404181</td>\n",
       "      <td>0.467359</td>\n",
       "      <td>0.827464</td>\n",
       "      <td>0.318840</td>\n",
       "      <td>0.564090</td>\n",
       "      <td>0.929721</td>\n",
       "      <td>0.302227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.460593</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.485009</td>\n",
       "      <td>0.443293</td>\n",
       "      <td>0.004724</td>\n",
       "      <td>0.261294</td>\n",
       "      <td>0.511497</td>\n",
       "      <td>0.020496</td>\n",
       "      <td>0.491749</td>\n",
       "      <td>0.491372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488753</td>\n",
       "      <td>0.505637</td>\n",
       "      <td>0.865306</td>\n",
       "      <td>0.403213</td>\n",
       "      <td>0.464749</td>\n",
       "      <td>0.823157</td>\n",
       "      <td>0.317672</td>\n",
       "      <td>0.565175</td>\n",
       "      <td>0.929758</td>\n",
       "      <td>0.302525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.460616</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.484947</td>\n",
       "      <td>0.443291</td>\n",
       "      <td>0.004507</td>\n",
       "      <td>0.261638</td>\n",
       "      <td>0.511557</td>\n",
       "      <td>0.020561</td>\n",
       "      <td>0.491635</td>\n",
       "      <td>0.491757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.487847</td>\n",
       "      <td>0.505315</td>\n",
       "      <td>0.863186</td>\n",
       "      <td>0.401749</td>\n",
       "      <td>0.463125</td>\n",
       "      <td>0.820512</td>\n",
       "      <td>0.315651</td>\n",
       "      <td>0.566229</td>\n",
       "      <td>0.929575</td>\n",
       "      <td>0.302024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   left_foot_X  left_foot_Y  left_foot_Z  right_foot_X  right_foot_Y  \\\n",
       "0     0.460614     0.000166     0.485203      0.443349      0.005469   \n",
       "1     0.460578     0.000136     0.485146      0.443353      0.005227   \n",
       "2     0.460574     0.000120     0.485081      0.443325      0.004967   \n",
       "3     0.460593     0.000099     0.485009      0.443293      0.004724   \n",
       "4     0.460616     0.000089     0.484947      0.443291      0.004507   \n",
       "\n",
       "   right_foot_Z  left_ank_X  left_ank_Y  left_ank_Z  right_ank_X  ...  \\\n",
       "0      0.260588    0.511488    0.020407    0.492017     0.490406  ...   \n",
       "1      0.260808    0.511440    0.020438    0.491954     0.490729  ...   \n",
       "2      0.261057    0.511433    0.020473    0.491871     0.491071  ...   \n",
       "3      0.261294    0.511497    0.020496    0.491749     0.491372  ...   \n",
       "4      0.261638    0.511557    0.020561    0.491635     0.491757  ...   \n",
       "\n",
       "   left_shoulder_Z  shoulder_center_X  shoulder_center_Y  shoulder_center_Z  \\\n",
       "0         0.491060           0.507807           0.875500           0.406681   \n",
       "1         0.490244           0.507147           0.871966           0.405486   \n",
       "2         0.489521           0.506239           0.868436           0.404181   \n",
       "3         0.488753           0.505637           0.865306           0.403213   \n",
       "4         0.487847           0.505315           0.863186           0.401749   \n",
       "\n",
       "   right_shoulder_X  right_shoulder_Y  right_shoulder_Z    head_X    head_Y  \\\n",
       "0          0.472630          0.837056          0.322301  0.561631  0.929868   \n",
       "1          0.470012          0.832011          0.320728  0.562917  0.929760   \n",
       "2          0.467359          0.827464          0.318840  0.564090  0.929721   \n",
       "3          0.464749          0.823157          0.317672  0.565175  0.929758   \n",
       "4          0.463125          0.820512          0.315651  0.566229  0.929575   \n",
       "\n",
       "     head_Z  \n",
       "0  0.303745  \n",
       "1  0.303000  \n",
       "2  0.302227  \n",
       "3  0.302525  \n",
       "4  0.302024  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 946,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reducedMarkerNames = ['left_foot',      # 0\n",
    "                      'right_foot',     # 1          \n",
    "                      'left_ank',       # 2      \n",
    "                      'right_ank',      # 3                          \n",
    "                      'left_knee',      # 4                          \n",
    "                      'right_knee',     # 5                              \n",
    "                      'left_hip',       # 6                          \n",
    "                      'hip_central',    # 7                              \n",
    "                      'right_hip',      # 8                          \n",
    "                      'spine',          # 9                       \n",
    "                      'left_hand',      # 10                           \n",
    "                      'right_hand',     # 11                               \n",
    "                      'left_wrist',     # 12                               \n",
    "                      'right_wrist',    # 13                               \n",
    "                      'left_elbow',     # 14                               \n",
    "                      'right_elbow',    # 15                               \n",
    "                      'left_shoulder',  # 16                               \n",
    "                      'shoulder_center',# 17                                   \n",
    "                      'right_shoulder', # 18                                   \n",
    "                      'head']           # 19                       \n",
    "fullMarkerNames = [colname[:-2] for colname in list(data.iloc[:1,3::3].columns)]\n",
    "reduced20MarkersToFullMarkers = map_reduce_num_markers(reducedMarkerNames)\n",
    "reduced20MarkersToFullMarkersX = {key+'_X': [elem+' X' for elem in reduced20MarkersToFullMarkers[key]] for key in reduced20MarkersToFullMarkers.keys()}\n",
    "reduced20MarkersToFullMarkersY = {key+'_Y': [elem+' Y' for elem in reduced20MarkersToFullMarkers[key]] for key in reduced20MarkersToFullMarkers.keys()}\n",
    "reduced20MarkersToFullMarkersZ = {key+'_Z': [elem+' Z' for elem in reduced20MarkersToFullMarkers[key]] for key in reduced20MarkersToFullMarkers.keys()}\n",
    "\n",
    "posTable = data.iloc[:,3:]\n",
    "\n",
    "posTableX = posTable.iloc[:,::3]\n",
    "posTableY = posTable.iloc[:,1::3]\n",
    "posTableZ = posTable.iloc[:,2::3]\n",
    "\n",
    "reducedPosTableX = pd.concat([posTableX[reduced20MarkersToFullMarkersX[colName+'_X']].mean(axis=1) for colName in reducedMarkerNames],axis=1,keys=[name+'_X' for name in reducedMarkerNames])\n",
    "reducedPosTableY = pd.concat([posTableY[reduced20MarkersToFullMarkersY[colName+'_Y']].mean(axis=1) for colName in reducedMarkerNames],axis=1,keys=[name+'_Y' for name in reducedMarkerNames])\n",
    "reducedPosTableZ = pd.concat([posTableZ[reduced20MarkersToFullMarkersZ[colName+'_Z']].mean(axis=1) for colName in reducedMarkerNames],axis=1,keys=[name+'_Z' for name in reducedMarkerNames])\n",
    "\n",
    "#reducedPosTableX = (reducedPosTableX - reducedPosTableX.min(axis=None))/(reducedPosTableX.max(axis=None)-reducedPosTableX.min(axis=None))\n",
    "#reducedPosTableY = (reducedPosTableY - reducedPosTableY.min(axis=None))/(reducedPosTableY.max(axis=None)-reducedPosTableY.min(axis=None))\n",
    "#reducedPosTableZ = (reducedPosTableZ - reducedPosTableZ.min(axis=None))/(reducedPosTableZ.max(axis=None)-reducedPosTableZ.min(axis=None))\n",
    "\n",
    "def xyz_tables_to_xyz_columns(tablesList):\n",
    "    xTable,yTable,zTable = tablesList\n",
    "    mergedTable = pd.DataFrame()\n",
    "    for joint in range(xTable.shape[1]):\n",
    "        mergedTable = pd.concat([mergedTable,xTable.iloc[:,joint],yTable.iloc[:,joint],zTable.iloc[:,joint]],axis=1)\n",
    "    return mergedTable\n",
    "\n",
    "reducedPosTable = xyz_tables_to_xyz_columns([reducedPosTableX,reducedPosTableY,reducedPosTableZ])\n",
    "reducedPosTable = (reducedPosTable - reducedPosTable.min(axis=None))/(reducedPosTable.max(axis=None)-reducedPosTable.min(axis=None))\n",
    "reducedPosTable.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to files final clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PROCESSED_PATH = 'data/reprocessed/'\n",
    "\n",
    "dest_dir = os.path.join(PROCESSED_PATH,folder)\n",
    "if not os.path.exists(dest_dir): \n",
    "    os.mkdir(dest_dir)\n",
    "dest_file_path = os.path.join(dest_dir,trial+'_frag'+fragId+'.csv')\n",
    "if not os.path.isfile(dest_file_path):\n",
    "    reducedPosTable.to_csv(dest_file_path,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting reduced markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib\n",
    "from matplotlib.widgets import Slider\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "if sampleAnno < 45:\n",
    "    posTableY = reducedPosTable.iloc[:,::3]\n",
    "    posTableZ = reducedPosTable.iloc[:,1::3]\n",
    "    posTableX = reducedPosTable.iloc[:,2::3]\n",
    "else:\n",
    "    posTableX = reducedPosTable.iloc[:,::3]\n",
    "    posTableY = reducedPosTable.iloc[:,1::3]\n",
    "    posTableZ = reducedPosTable.iloc[:,2::3]\n",
    "\n",
    "jointsFrom = [1, 3, 5, 7, 2, 4, 6, 9, 8,10,11,13,15,17,12,14,16,19,18]\n",
    "jointsTo =   [3, 5, 7, 8, 4, 6, 9, 8,10,18,13,15,17,18,14,16,19,18,20]\n",
    "jointsFrom = list(map(lambda x: x-1,jointsFrom))\n",
    "jointsTo = list(map(lambda x: x-1,jointsTo))\n",
    "edges = np.array(list(zip(jointsFrom,jointsTo))+list(zip(jointsTo,jointsFrom)))\n",
    "adjacencyMatrix = np.zeros((20,20),dtype=bool)\n",
    "adjacencyMatrix[edges[:,0],edges[:,1]] = True\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig = plt.figure()\n",
    "ax:plt.Axes = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "minMax = np.zeros((2,3))\n",
    "minMax[0,:] = [np.nanmin(posTableX.values),np.nanmin(posTableY.values),np.nanmin(posTableZ.values)]\n",
    "minMax[1,:] = [np.nanmax(posTableX.values),np.nanmax(posTableY.values),np.nanmax(posTableZ.values)]\n",
    "\n",
    "# Set the window title\n",
    "fig.canvas.manager.window.title(\"3D Movement\\t(Scroll with mouse wheel)\")\n",
    "\n",
    "# Set the initial time index\n",
    "time_index = 0\n",
    "\n",
    "# Function to update the plot based on the slider value\n",
    "def update_plot(val):\n",
    "    ax.cla()  # Clear the previous plot\n",
    "    \n",
    "    # Filter the data based on the current time index\n",
    "    filteredX = posTableX.iloc[val]\n",
    "    filteredY = posTableY.iloc[val]\n",
    "    filteredZ = posTableZ.iloc[val]\n",
    "    \n",
    "    ax.scatter(filteredX,filteredY,filteredZ)\n",
    "\n",
    "    # Add edges based on the weight matrix\n",
    "    for i in range(20):\n",
    "        for j in range(i + 1, 20):\n",
    "            if adjacencyMatrix[i,j]:\n",
    "                ax.plot([filteredX[i], filteredX[j]],\n",
    "                        [filteredY[i], filteredY[j]],\n",
    "                        [filteredZ[i], filteredZ[j]],\n",
    "                        color='gray', linestyle='-', linewidth=1)\n",
    "\n",
    "    ax.set_xlim([-0.1,0.8])#minMax[0,0],minMax[1,0]])\n",
    "    ax.set_ylim([-0.1,0.8])#minMax[0,1],minMax[1,1]])\n",
    "    ax.set_zlim([minMax[0,2],minMax[1,2]])\n",
    "\n",
    "    ax.set_xlabel('X', fontsize=12)\n",
    "    ax.set_ylabel('Y', fontsize=12)\n",
    "    ax.set_zlabel('Z', fontsize=12)\n",
    "    ax.set_title(\"Movement \"+str(sampleAnno))\n",
    "\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "# Create a slider widget\n",
    "slider_ax = plt.axes([0.2, 0.03, 0.6, 0.03])\n",
    "maxValue = posTable.shape[0]-1\n",
    "slider = Slider(slider_ax, 'TimeIndex:', 0, maxValue, valinit=time_index, valstep=1)\n",
    "\n",
    "\n",
    "# Define a function to update the slider value with the mouse wheel\n",
    "def on_scroll(event):\n",
    "    if event.button == 'down':\n",
    "        if slider.val + slider.valstep*2 <= maxValue:\n",
    "            slider.set_val(slider.val + slider.valstep*2)\n",
    "    elif event.button == 'up':\n",
    "        if slider.val - slider.valstep*2 >= 0:\n",
    "            slider.set_val(slider.val - slider.valstep*2)\n",
    "        \n",
    "\n",
    "# Connect the mouse wheel event to the function\n",
    "fig.canvas.mpl_connect('scroll_event', on_scroll)\n",
    "\n",
    "\n",
    "# Register the update_plot function with the slider widget\n",
    "slider.on_changed(update_plot)\n",
    "\n",
    "# Initial plot\n",
    "update_plot(time_index)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting full markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib\n",
    "from matplotlib.widgets import Slider\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "if sampleAnno < 45:\n",
    "    posTableY = posTable.iloc[:,::3]\n",
    "    posTableZ = posTable.iloc[:,1::3]\n",
    "    posTableX = posTable.iloc[:,2::3]\n",
    "else:\n",
    "    posTableX = posTable.iloc[:,::3]\n",
    "    posTableY = posTable.iloc[:,1::3]\n",
    "    posTableZ = posTable.iloc[:,2::3]\n",
    "    \n",
    "\n",
    "plt.close(\"all\")\n",
    "fig = plt.figure()\n",
    "ax:plt.Axes = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "minMax = np.zeros((2,3))\n",
    "minMax[0,:] = [np.nanmin(posTableX.values),np.nanmin(posTableY.values),np.nanmin(posTableZ.values)]\n",
    "minMax[1,:] = [np.nanmax(posTableX.values),np.nanmax(posTableY.values),np.nanmax(posTableZ.values)]\n",
    "\n",
    "# Set the window title\n",
    "fig.canvas.manager.window.title(\"3D Movement\\t(Scroll with mouse wheel)\")\n",
    "\n",
    "# Set the initial time index\n",
    "time_index = 0\n",
    "\n",
    "# Function to update the plot based on the slider value\n",
    "def update_plot(val):\n",
    "    ax.cla()  # Clear the previous plot\n",
    "    \n",
    "    # Filter the data based on the current time index\n",
    "    filteredX = posTableX.iloc[val]\n",
    "    filteredY = posTableY.iloc[val]\n",
    "    filteredZ = posTableZ.iloc[val]\n",
    "    \n",
    "    ax.scatter(filteredX,filteredY,filteredZ)\n",
    "\n",
    "    ax.set_xlim([minMax[0,0],minMax[1,0]])\n",
    "    ax.set_ylim([minMax[0,1],minMax[1,1]])\n",
    "    ax.set_zlim([minMax[0,2],minMax[1,2]])\n",
    "\n",
    "    ax.set_xlabel('X', fontsize=12)\n",
    "    ax.set_ylabel('Y', fontsize=12)\n",
    "    ax.set_zlabel('Z', fontsize=12)\n",
    "    #ax.set_title(\"Movement \"+str(picked))\n",
    "\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "# Create a slider widget\n",
    "slider_ax = plt.axes([0.2, 0.03, 0.6, 0.03])\n",
    "maxValue = posTable.shape[0]-1\n",
    "slider = Slider(slider_ax, 'TimeIndex:', 0, maxValue, valinit=time_index, valstep=1)\n",
    "\n",
    "\n",
    "# Define a function to update the slider value with the mouse wheel\n",
    "def on_scroll(event):\n",
    "    if event.button == 'down':\n",
    "        if slider.val + slider.valstep*2 <= maxValue:\n",
    "            slider.set_val(slider.val + slider.valstep*2)\n",
    "    elif event.button == 'up':\n",
    "        if slider.val - slider.valstep*2 >= 0:\n",
    "            slider.set_val(slider.val - slider.valstep*2)\n",
    "        \n",
    "\n",
    "# Connect the mouse wheel event to the function\n",
    "fig.canvas.mpl_connect('scroll_event', on_scroll)\n",
    "\n",
    "\n",
    "# Register the update_plot function with the slider widget\n",
    "slider.on_changed(update_plot)\n",
    "\n",
    "# Initial plot\n",
    "update_plot(time_index)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib\n",
    "from matplotlib.widgets import Slider\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig = plt.figure()\n",
    "ax:plt.Axes = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "minMax = np.zeros((2,3))\n",
    "minMax[0,:] = [np.nanmin(posTableX.values),np.nanmin(posTableY.values),np.nanmin(posTableZ.values)]\n",
    "minMax[1,:] = [np.nanmax(posTableX.values),np.nanmax(posTableY.values),np.nanmax(posTableZ.values)]\n",
    "\n",
    "minMax[0,:] = [np.nanmin(posTableX.iloc[:1,:].values),np.nanmin(posTableY.iloc[:1,:].values),np.nanmin(posTableZ.iloc[:1,:].values)]\n",
    "minMax[1,:] = [np.nanmax(posTableX.iloc[:1,:].values),np.nanmax(posTableY.iloc[:1,:].values),np.nanmax(posTableZ.iloc[:1,:].values)]\n",
    "\n",
    "# Set the window title\n",
    "fig.canvas.manager.window.title(\"3D Movement\\t(Scroll with mouse wheel)\")\n",
    "\n",
    "# Set the initial time index\n",
    "time_index = 0\n",
    "\n",
    "# Function to update the plot based on the slider value\n",
    "def update_plot(val):\n",
    "    ax.cla()  # Clear the previous plot\n",
    "    \n",
    "    # Filter the data based on the current time index\n",
    "    filteredX = posTableX.iloc[val]\n",
    "    filteredY = posTableY.iloc[val]\n",
    "    filteredZ = posTableZ.iloc[val]\n",
    "    \n",
    "    ax.scatter(filteredX,filteredY,filteredZ,s=0)\n",
    "    \n",
    "    for i, col_name in enumerate(posTableX.columns):\n",
    "        ax.text(filteredX[i], filteredY[i], filteredZ[i], col_name[:-2], horizontalalignment='center',fontsize=6, color='black')\n",
    "\n",
    "    ax.set_xticks([minMax[0,0],minMax[1,0]])\n",
    "    ax.set_yticks([minMax[0,1],minMax[1,1]])\n",
    "    ax.set_zticks([minMax[0,2],minMax[1,2]])\n",
    "    ax.set_xlim([minMax[0,0],minMax[1,0]])\n",
    "    ax.set_ylim([minMax[0,1],minMax[1,1]])\n",
    "    ax.set_zlim([minMax[0,2],minMax[1,2]])\n",
    "    \n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "# Create a slider widget\n",
    "slider_ax = plt.axes([0.2, 0.03, 0.6, 0.03])\n",
    "maxValue = posTable.shape[0]-1\n",
    "slider = Slider(slider_ax, 'TimeIndex:', 0, maxValue, valinit=time_index, valstep=1)\n",
    "\n",
    "\n",
    "# Define a function to update the slider value with the mouse wheel\n",
    "def on_scroll(event):\n",
    "    if event.button == 'down':\n",
    "        if slider.val + slider.valstep*2 <= maxValue:\n",
    "            slider.set_val(slider.val + slider.valstep*2)\n",
    "    elif event.button == 'up':\n",
    "        if slider.val - slider.valstep*2 >= 0:\n",
    "            slider.set_val(slider.val - slider.valstep*2)\n",
    "        \n",
    "\n",
    "# Connect the mouse wheel event to the function\n",
    "fig.canvas.mpl_connect('scroll_event', on_scroll)\n",
    "\n",
    "\n",
    "# Register the update_plot function with the slider widget\n",
    "slider.on_changed(update_plot)\n",
    "\n",
    "# Initial plot\n",
    "update_plot(time_index)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All in One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555d01150e9948f9abc1eadc9b1ed4bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving samples:   0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import csv\n",
    "def custom_header_reader(file:'TextIOWrapper'):\n",
    "    csvReader = csv.reader(file,delimiter='\\t')\n",
    "    for row, text in enumerate(csvReader):\n",
    "        if row == 2: numMarkers = int(text[-1])\n",
    "        elif row == 10: \n",
    "            columnNames = text[:-1]\n",
    "            if columnNames[0] == 'Frame': \n",
    "                break\n",
    "        elif row == 11: columnNames = text[:-1]; break\n",
    "    return numMarkers, columnNames, csvReader\n",
    "\n",
    "def line_reader(csvReader,fromSecond,toSecond):\n",
    "    for line in csvReader:\n",
    "        if fromSecond <= float(line[1]) <= toSecond:\n",
    "            yield line[:len(columnNames)]\n",
    "        elif float(line[1]) > toSecond:\n",
    "            break\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "ANNOTATIONS_PATH = 'data'\n",
    "RAW_PATH = ANNOTATIONS_PATH+'/raw'\n",
    "#with open(ANNOTATIONS_PATH+'/annotations.txt','r') as file:\n",
    "#    annotations = file.read().splitlines()\n",
    "with open(ANNOTATIONS_PATH+'/annotationsVReduced.txt','r') as file:\n",
    "    annotations = file.read().splitlines()[1:]#[line for line in file.read().splitlines() if 'no val' in line]\n",
    "    #print(len(annotations))\n",
    "    \n",
    "for sampleAnno in tqdm(range(-len(annotations)),desc=\"Saving samples\"):\n",
    "    if '(A)' in annotations[sampleAnno] or '(B)' in annotations[sampleAnno]:\n",
    "        folder, trial, fragId, side, OoM, startSec, endSec = annotations[sampleAnno].replace(' ','').split(',')[:7]\n",
    "    else:\n",
    "        folder, trial, fragId, OoM, startSec, endSec = annotations[sampleAnno].replace(' ','').split(',')[:6]\n",
    "    sampleData = os.path.join(RAW_PATH,folder,trial+'.tsv')\n",
    "    #print(sampleData,startSec,endSec)\n",
    "    with open(sampleData,'r') as file:\n",
    "        numMarkers, columnNames, readerBuffer = custom_header_reader(file)\n",
    "        data = pd.DataFrame(line_reader(readerBuffer,float(startSec),float(endSec)),columns=columnNames).astype(dict(zip(columnNames,[int,float,str]+[float]*len(columnNames[3:]))))\n",
    "    #print(data['Time'])\n",
    "    #print(sampleAnno, data['Time'].iloc[0])\n",
    "    if data['Time'].iloc[0] > float(startSec) or data['Time'].iloc[-1] < float(endSec):\n",
    "        raise Exception(f'\\x1b[31mNOT FULL FRAMES!!! data starts at: {data[\"Time\"].iloc[0]} of {float(startSec)} and ends at {data[\"Time\"].iloc[-1]} of {float(endSec)}\\x1b[0m')\n",
    "    else:\n",
    "        #print(\"\\x1b[32mSTART AND END SECONDS CHECK CORRECT!\\x1b[0m\")\n",
    "        pass\n",
    "\n",
    "\n",
    "    import pandas as pd\n",
    "    if '_A' in data.columns[3] or '_B' in data.columns[3]:\n",
    "        data = data[['Frame','Time','SMPTE']+data.filter(like=f'_{side[1]}').columns.tolist()]\n",
    "        data.columns = [col.replace(f'_{side[1]}','') for col in data.columns]\n",
    "    elif '61A' in data.columns[3] or '61B' in data.columns[3]:\n",
    "        data = data[['Frame','Time','SMPTE']+data.filter(like=f'61{side[1]}').columns.tolist()]\n",
    "        data.columns = [col.replace(f'61{side[1]}_','') for col in data.columns]\n",
    "    if '_01' in data.columns[3]:\n",
    "        data.columns = [column for column in data.columns[:3]]+[column[:-5]+column[-2:] for column in data.columns[3:]]\n",
    "    if 'HeadFront' in data.columns[3] or 'RKneeIn' in data.columns[3]:\n",
    "        mappings = pd.read_csv(\"data/raw/ExtendedMarkersToStandard.csv\")\n",
    "        mappings = mappings.set_index(mappings.columns[0])[mappings.columns[1]].to_dict()\n",
    "        data.columns = [mappings[col[:-2]]+col[-2:] if col[:-2] in mappings.keys() else col for col in data.columns]\n",
    "\n",
    "\n",
    "    #print(\"Total NaNs\")\n",
    "    nans = data[data.columns[(data.isna().sum(axis=0) > 0 ).to_list()]].isna().sum(axis=0).sort_values(ascending=False)\n",
    "    color = '\\x1b[32m' if len(nans) == 0 else '\\x1b[31m'\n",
    "    #print(color+str(nans)+'\\x1b[0m '+ ('\\nNo Nans' if len(nans)==0 else '\\nNans found!'))\n",
    "\n",
    "    from itertools import groupby\n",
    "    max_nans_per_column = data.apply(lambda col: max(len(list(group))*value for value, group in groupby(col.isna().tolist())))\n",
    "    #print(\"Max contiguous NaNs\")\n",
    "    max_nans_per_column = max_nans_per_column[max_nans_per_column > 0].sort_values(ascending=False)\n",
    "    color = '\\x1b[32m' if len(max_nans_per_column) == 0 else '\\x1b[31m'\n",
    "    #print(color+str(max_nans_per_column)+'\\x1b[0m ' + ('\\nNo Nans' if len(nans)==0 else '\\nNans found!'))\n",
    "\n",
    "    #print('Num Zeros')\n",
    "    zeros = data[data.columns[(data.eq(0.0).sum(axis=0) > 0).to_list()]].eq(0.0).sum(axis=0).sort_values(ascending=False)\n",
    "    color = '\\x1b[32m' if len(zeros) == 0 else '\\x1b[31m'\n",
    "    #print(color+str(zeros)+'\\x1b[0m ' + ('\\nNo Zeros' if len(zeros)==0 else '\\nZeros found!'))\n",
    "    #list(zeros.index)\n",
    "\n",
    "    # THIS IS A FIX FOR MISSING QTM AT DATA 58-59\n",
    "    import numpy as np\n",
    "    if len(zeros.index) > 15:\n",
    "        for name_col,num_zeros in zeros.items():\n",
    "            if num_zeros < 50:\n",
    "                data[name_col] = data[name_col].replace(0.0,np.nan).interpolate(method='spline', order=3)\n",
    "\n",
    "\n",
    "    from itertools import groupby\n",
    "    max_zeros_per_column = data.apply(lambda col: max(len(list(group))*value for value, group in groupby(col.eq(0.0).tolist())))\n",
    "    #print(\"Max contiguous Zeros\")\n",
    "    max_zeros_per_column = max_zeros_per_column[max_zeros_per_column > 0].sort_values(ascending=False)\n",
    "    color = '\\x1b[32m' if len(max_zeros_per_column) == 0 else '\\x1b[31m'\n",
    "    #print(color+str(max_zeros_per_column)+'\\x1b[0m ' + ('\\nNo Zeros' if len(max_zeros_per_column)==0 else '\\nZeros found!'))\n",
    "\n",
    "\n",
    "    def map_reduce_num_markers(reducedMarkerNames:list):\n",
    "        if not 'ARIEL' in fullMarkerNames:\n",
    "            pass\n",
    "        markersMap = {reducedMarkerNames[0]:   ['RHEL','RMT1','RMT5','RTOE'],\n",
    "                      reducedMarkerNames[1]:   ['LHEL','LMT1','LMT5','LTOE'],\n",
    "                      reducedMarkerNames[2]:   ['RANK'],\n",
    "                      reducedMarkerNames[3]:   ['LANK'],\n",
    "                      reducedMarkerNames[4]:   ['RKNE','RKNI'],\n",
    "                      reducedMarkerNames[5]:   ['LKNE','LKNI'],\n",
    "                      reducedMarkerNames[6]:   ['RFWT','RBWT'],\n",
    "                      reducedMarkerNames[7]:   ['RFWT','LFWT','RBWT','LBWT'],\n",
    "                      reducedMarkerNames[8]:   ['LFWT','LBWT'],\n",
    "                      reducedMarkerNames[9]:   ['C6','C7','T5','T10','BWT','STRN','CLAV','FWT'],\n",
    "                      reducedMarkerNames[10]:  ['RPLM','RTHMB','RINDX','RMID','RPNKY'],\n",
    "                      reducedMarkerNames[11]:  ['LPLM','LTHMB','LINDX','LMID','LPNKY'],\n",
    "                      reducedMarkerNames[12]:  ['ROWR','RIWR'],\n",
    "                      reducedMarkerNames[13]:  ['LOWR','LIWR'],\n",
    "                      reducedMarkerNames[14]:  ['RELB','RIEL','RFRM'],\n",
    "                      reducedMarkerNames[15]:  ['LELB','LIEL','LFRM'],\n",
    "                      reducedMarkerNames[16]:  ['RSHO'],\n",
    "                      reducedMarkerNames[17]:  ['RSHO','LSHO'],\n",
    "                      reducedMarkerNames[18]:  ['LSHO'],\n",
    "                      reducedMarkerNames[19]:  ['ARIEL','RFHD','LFHD','RBHD','LBHD']\n",
    "                      }\n",
    "        \n",
    "        # removing nan joints\n",
    "        for nan_joint_name,_ in max_nans_per_column[::3].items():\n",
    "            nan_joint_name = nan_joint_name[:-2]\n",
    "            for markerFullList in markersMap.values():\n",
    "                if nan_joint_name in markerFullList:\n",
    "                    markerFullList.remove(nan_joint_name)\n",
    "                    break\n",
    "        # removing many contiguous zeros joints\n",
    "        for zero_joint_name,contiguous_zeros in max_zeros_per_column[::3].items():\n",
    "            if contiguous_zeros > 20:\n",
    "                zero_joint_name = zero_joint_name[:-2]\n",
    "                for markerFullList in markersMap.values():\n",
    "                    if zero_joint_name in markerFullList:\n",
    "                        markerFullList.remove(zero_joint_name)\n",
    "                        break\n",
    "        originalDataColumns = [colname[:-2] for colname in list(data.iloc[:1,3::3].columns)]\n",
    "\n",
    "        # removing markers not present in the data markers\n",
    "        for markerFullList in markersMap.values():\n",
    "            for markerName in list(reversed(markerFullList)):\n",
    "                if not markerName in originalDataColumns:\n",
    "                    markerFullList.remove(markerName)\n",
    "\n",
    "        # removing asymmetries across body\n",
    "        for right_side_marker_indx,left_side_marker_indx in [(0,1),(2,3),(4,5),(6,8),(10,11),(12,13),(14,15),(16,18)]: # indices of every marker on the left side and his symmetric\n",
    "            markersLeft = markersMap[reducedMarkerNames[left_side_marker_indx]]\n",
    "            markersRight = markersMap[reducedMarkerNames[right_side_marker_indx]]\n",
    "            for elem in markersLeft:\n",
    "                if not 'R'+elem[1:] in markersRight:\n",
    "                    markersLeft.remove(elem)\n",
    "                    if left_side_marker_indx == 6 or left_side_marker_indx == 16: \n",
    "                        markersMap[reducedMarkerNames[left_side_marker_indx+1]].remove(elem)\n",
    "            for elem in markersRight:\n",
    "                if not 'L'+elem[1:] in markersLeft:\n",
    "                    markersRight.remove(elem)\n",
    "                    if right_side_marker_indx == 8 or right_side_marker_indx == 18: \n",
    "                        markersMap[reducedMarkerNames[right_side_marker_indx-1]].remove(elem)\n",
    "\n",
    "        for i,markerFullList in enumerate(markersMap.values()):\n",
    "            if len(markerFullList) == 0:\n",
    "                print(markersMap)\n",
    "                raise Exception(f\"can't reconstruct '{reducedMarkerNames[i]}' of 20 markers, because every marker of the full set is missing!!\")\n",
    "        return markersMap\n",
    "\n",
    "    reducedMarkerNames = ['right_foot',      # 1\n",
    "                          'left_foot',       # 2        \n",
    "                          'right_ank',       # 3      \n",
    "                          'left_ank',        # 4                          \n",
    "                          'right_knee',      # 5                          \n",
    "                          'left_knee',       # 6                              \n",
    "                          'right_hip',       # 7                          \n",
    "                          'hip_central',     # 8                              \n",
    "                          'left_hip',        # 9                          \n",
    "                          'spine',           # 10                       \n",
    "                          'right_hand',      # 11                           \n",
    "                          'left_hand',       # 12                               \n",
    "                          'right_wrist',     # 13                               \n",
    "                          'left_wrist',      # 14                               \n",
    "                          'right_elbow',     # 15                               \n",
    "                          'left_elbow',      # 16                               \n",
    "                          'right_shoulder',  # 17                               \n",
    "                          'shoulder_center', # 18                                   \n",
    "                          'left_shoulder',   # 19                                   \n",
    "                          'head']            # 20                       \n",
    "    fullMarkerNames = [colname[:-2] for colname in list(data.iloc[:1,3::3].columns)]\n",
    "    reduced20MarkersToFullMarkers = map_reduce_num_markers(reducedMarkerNames)\n",
    "    reduced20MarkersToFullMarkersX = {key+'_X': [elem+' X' for elem in reduced20MarkersToFullMarkers[key]] for key in reduced20MarkersToFullMarkers.keys()}\n",
    "    reduced20MarkersToFullMarkersY = {key+'_Y': [elem+' Y' for elem in reduced20MarkersToFullMarkers[key]] for key in reduced20MarkersToFullMarkers.keys()}\n",
    "    reduced20MarkersToFullMarkersZ = {key+'_Z': [elem+' Z' for elem in reduced20MarkersToFullMarkers[key]] for key in reduced20MarkersToFullMarkers.keys()}\n",
    "\n",
    "    posTable = data.iloc[:,3:]\n",
    "\n",
    "    posTableX = posTable.iloc[:,::3]\n",
    "    posTableY = posTable.iloc[:,1::3]\n",
    "    posTableZ = posTable.iloc[:,2::3]\n",
    "\n",
    "    reducedPosTableX = pd.concat([posTableX[reduced20MarkersToFullMarkersX[colName+'_X']].mean(axis=1) for colName in reducedMarkerNames],axis=1,keys=[name+'_X' for name in reducedMarkerNames])\n",
    "    reducedPosTableY = pd.concat([posTableY[reduced20MarkersToFullMarkersY[colName+'_Y']].mean(axis=1) for colName in reducedMarkerNames],axis=1,keys=[name+'_Y' for name in reducedMarkerNames])\n",
    "    reducedPosTableZ = pd.concat([posTableZ[reduced20MarkersToFullMarkersZ[colName+'_Z']].mean(axis=1) for colName in reducedMarkerNames],axis=1,keys=[name+'_Z' for name in reducedMarkerNames])\n",
    "\n",
    "    #reducedPosTableX = (reducedPosTableX - reducedPosTableX.min(axis=None))/(reducedPosTableX.max(axis=None)-reducedPosTableX.min(axis=None))\n",
    "    #reducedPosTableY = (reducedPosTableY - reducedPosTableY.min(axis=None))/(reducedPosTableY.max(axis=None)-reducedPosTableY.min(axis=None))\n",
    "    #reducedPosTableZ = (reducedPosTableZ - reducedPosTableZ.min(axis=None))/(reducedPosTableZ.max(axis=None)-reducedPosTableZ.min(axis=None))\n",
    "\n",
    "    def xyz_tables_to_xyz_columns(tablesList):\n",
    "        xTable,yTable,zTable = tablesList\n",
    "        mergedTable = pd.DataFrame()\n",
    "        for joint in range(xTable.shape[1]):\n",
    "            mergedTable = pd.concat([mergedTable,xTable.iloc[:,joint],yTable.iloc[:,joint],zTable.iloc[:,joint]],axis=1)\n",
    "        return mergedTable\n",
    "\n",
    "    reducedPosTable = xyz_tables_to_xyz_columns([reducedPosTableX,reducedPosTableY,reducedPosTableZ])\n",
    "    reducedPosTable = (reducedPosTable - reducedPosTable.min(axis=None))/(reducedPosTable.max(axis=None)-reducedPosTable.min(axis=None))\n",
    "    reducedPosTable.head()\n",
    "\n",
    "    import os\n",
    "\n",
    "    PROCESSED_PATH = 'data/reprocessed/'\n",
    "\n",
    "    dest_dir = os.path.join(PROCESSED_PATH,folder)\n",
    "    if not os.path.exists(dest_dir): \n",
    "        os.mkdir(dest_dir)\n",
    "    dest_file_path = os.path.join(dest_dir,trial+'_frag'+fragId+'.csv')\n",
    "    if not os.path.isfile(dest_file_path) or True:\n",
    "        reducedPosTable.to_csv(dest_file_path,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
