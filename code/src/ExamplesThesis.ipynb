{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video next to Skeleton64 next to Skeleton20  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import csv\n",
    "def custom_header_reader(file:'TextIOWrapper'):\n",
    "    csvReader = csv.reader(file,delimiter='\\t')\n",
    "    for row, text in enumerate(csvReader):\n",
    "        if row == 2: numMarkers = int(text[-1])\n",
    "        elif row == 10: \n",
    "            columnNames = text[:-1]\n",
    "            if columnNames[0] == 'Frame': \n",
    "                break\n",
    "        elif row == 11: columnNames = text[:-1]; break\n",
    "    return numMarkers, columnNames, csvReader\n",
    "\n",
    "def line_reader(csvReader,fromSecond,toSecond):\n",
    "    for line in csvReader:\n",
    "        if fromSecond <= float(line[1]) <= toSecond:\n",
    "            yield line[:len(columnNames)]\n",
    "        elif float(line[1]) > toSecond:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6196 entries, 0 to 6195\n",
      "Columns: 195 entries, Frame to LPLM Z\n",
      "dtypes: float64(193), int64(1), object(1)\n",
      "memory usage: 9.2+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "ANNOTATIONS_PATH = 'data'\n",
    "REPROCESSED_PATH = ANNOTATIONS_PATH+'/reprocessed'\n",
    "RAW_PATH = ANNOTATIONS_PATH+'/raw'\n",
    "#annotations_file = ANNOTATIONS_PATH+'/annotationsVSingle.txt'\n",
    "annotations_file = ANNOTATIONS_PATH+'/annotationsVExamples.txt' #'/annotationsVSingle.txt'\n",
    "\n",
    "with open(annotations_file,'r') as file:\n",
    "    annotations = file.read().splitlines()[1:]\n",
    "\n",
    "sampleAnno = 1\n",
    "\n",
    "if '(A)' in annotations[sampleAnno] or '(B)' in annotations[sampleAnno]:\n",
    "    folder, trial, fragId, _, OoM, startSec, endSec = annotations[sampleAnno].replace(' ','').split(',')[:7]\n",
    "else:\n",
    "    folder, trial, fragId, OoM, startSec, endSec = annotations[sampleAnno].replace(' ','').split(',')[:6]\n",
    "\n",
    "reprocessed_file = os.path.join(REPROCESSED_PATH, folder, trial+'_frag'+fragId+'.csv')\n",
    "reducedMarkersTable = pd.read_csv(reprocessed_file)\n",
    "raw_file = os.path.join(RAW_PATH, folder, trial+'.tsv')\n",
    "with open(raw_file,'r') as file:\n",
    "    numMarkers, columnNames, readerBuffer = custom_header_reader(file)\n",
    "    fullMarkersTable = pd.DataFrame(line_reader(readerBuffer,float(startSec),float(endSec)),columns=columnNames).astype(dict(zip(columnNames,[int,float,str]+[float]*len(columnNames[3:]))))\n",
    "fullMarkersTable.iloc[:,3:] = (fullMarkersTable.iloc[:,3:] - fullMarkersTable.iloc[:,3:].min(axis=None))/(fullMarkersTable.iloc[:,3:].max(axis=None)-fullMarkersTable.iloc[:,3:].min(axis=None))\n",
    "fullMarkersTable.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video face censoring\n",
    "TODO improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "# Load a pre-trained face detection model (e.g., Haar Cascade)\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "half_body_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_upperbody.xml')\n",
    "\n",
    "\n",
    "video_path = '/'.join(os.getcwd().split('/')[:-2]+['docs','presentation','resources','_'.join([folder,trial])+'.mp4'])\n",
    "\n",
    "vidcap = cv2.VideoCapture(video_path[:-4]+'_'+str(100)+'fps.mp4')\n",
    "\n",
    "# Get video details\n",
    "fps = int(vidcap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "num_frames = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Define a function to censor faces\n",
    "def censor_faces(frame,i):\n",
    "    if i < 5800:\n",
    "        frame_crop = frame[height//4:height//4+int(height/2.5),int(width/7.5):int(width/7.5)+int(width/2.1)]\n",
    "        gray = cv2.cvtColor(frame_crop, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray,scaleFactor=1.1, minNeighbors=5, minSize=(15, 15), maxSize=(40,40))\n",
    "    else:\n",
    "        frame_crop = frame[height//3:height//3+int(height/6),int(width/1.9):int(width/1.9)+int(width/6)]\n",
    "        gray = cv2.cvtColor(frame_crop, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.03, minNeighbors=1, minSize=(30, 30), maxSize=(40,40))\n",
    "    if not any(static_face_censor_delay) and len(faces) == 0:\n",
    "        gray = cv2.addWeighted(gray, 3.1, np.zeros_like(gray), 0, 0)\n",
    "        half_body = half_body_cascade.detectMultiScale(gray, scaleFactor=1.01, minNeighbors=5, minSize=(120, 120), maxSize=(200,200))\n",
    "        return *apply_censoring(frame,half_body,is_body=True), half_body\n",
    "    return *apply_censoring(frame,faces,i=i), faces\n",
    "\n",
    "def apply_censoring(frame, bb, i=-1, is_body=False):\n",
    "    for (x, y, w, h) in bb:\n",
    "        # Apply censorship here, e.g., pixelation\n",
    "        if is_body:\n",
    "            x += int(width/7.5) + 30 ; y += height//4 + 40\n",
    "            w = 60; h = 50\n",
    "        else:\n",
    "            if i < 5800:\n",
    "                enlarger = 4\n",
    "                x += int(width/7.5) - enlarger; y += height//4 - enlarger\n",
    "                w += 4*enlarger; h += 4*enlarger\n",
    "            else:\n",
    "                enlarger = 10\n",
    "                x += int(width/1.9)-enlarger ; y += height//3-enlarger\n",
    "                w += 2*enlarger; h += 2*enlarger\n",
    "        roi = frame[y:y+h,x:x+w]\n",
    "        roi = cv2.GaussianBlur(roi, (23, 23), 9)\n",
    "        frame[y:y+h, x:x+w] = roi\n",
    "    return frame, is_body\n",
    "\n",
    "static_face_window = 400\n",
    "static_face_censor_delay = np.zeros(static_face_window, bool)\n",
    "moving_face_window = 300\n",
    "moving_face_censor_delay = np.zeros(moving_face_window, bool)\n",
    "\n",
    "last_faces = None\n",
    "\n",
    "if not os.path.isfile(video_path[:-4]+'_face_censored.mp4'):\n",
    "    # Create an output video writer\n",
    "    out = cv2.VideoWriter(video_path[:-4]+'_face_censored.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "    _, frame = vidcap.read()\n",
    "    faces = [[477, 75, 30, 30]]\n",
    "    frame,_ = apply_censoring(frame, faces)\n",
    "    censored = True\n",
    "    is_body = False\n",
    "    for i in tqdm(range(1,num_frames), 'Blurring face',miniters=20):\n",
    "        if is_body:\n",
    "            moving_face_censor_delay[i%moving_face_window] = censored\n",
    "            static_face_censor_delay[i%static_face_window] = False\n",
    "        else:\n",
    "            static_face_censor_delay[i%static_face_window] = censored\n",
    "            moving_face_censor_delay[i%moving_face_window] = False\n",
    "\n",
    "        if censored:\n",
    "            last_faces = faces\n",
    "        if not censored and ((not is_body and any(static_face_censor_delay)) or (is_body and any(moving_face_censor_delay))):\n",
    "            frame,_ = apply_censoring(frame, last_faces, is_body=is_body)\n",
    "        #frame = cv2.rectangle(frame, (int(width/7.5), height//4), (int(width/7.5) + int(width/2.1), height//4 + int(height/2.5)), (255, 0, 0), 2)\n",
    "        # Add the text to the image\n",
    "        #frame = cv2.putText(frame, str(i), (40,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "        # Write the frame to the output video\n",
    "        out.write(frame)\n",
    "\n",
    "        _, frame = vidcap.read()\n",
    "        \n",
    "        # Apply censorship to the frame\n",
    "        frame, is_body, faces = censor_faces(frame,i)\n",
    "        censored = len(faces) > 0\n",
    "\n",
    "    out.release()\n",
    "vidcap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53856f2323a4437bb8bfca6cb52d4a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Subtracting BG: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "\n",
    "# Initializing the subtractor\n",
    "fgbg = cv2.createBackgroundSubtractorKNN(history=100,dist2Threshold=500)\n",
    "\n",
    "input_video = cv2.VideoCapture('video.mp4')\n",
    "\n",
    "frame_width = int(input_video.get(3))\n",
    "frame_height = int(input_video.get(4))\n",
    "fps = int(input_video.get(5))\n",
    "num_frames = int(input_video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "if not os.path.isfile('videoNoBG.mp4'):\n",
    "    output_video = cv2.VideoWriter('videoNoBG.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height), isColor=True)\n",
    "    \n",
    "    for i in tqdm(range(num_frames), 'Subtracting BG', miniters=40):\n",
    "        ret, frame = input_video.read()\n",
    "        \n",
    "        # Apply the background subtractor KNN\n",
    "        fgmask = fgbg.apply(frame)\n",
    "        \n",
    "        # Clean up the mask using morphological operations\n",
    "        fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        # Invert the mask to keep the foreground\n",
    "        fg = cv2.bitwise_and(frame, frame, mask=fgmask)\n",
    "        \n",
    "        # Save the frame to the output video\n",
    "        output_video.write(fg)\n",
    "    \n",
    "    output_video.release()\n",
    "    \n",
    "# Release the video objects\n",
    "input_video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Replace 'your_file.xml' with the actual XML file you want to read\n",
    "xml_file = ANNOTATIONS_PATH+'/labels.xml'\n",
    "\n",
    "# Parse the XML file\n",
    "root = ET.parse(xml_file).getroot()\n",
    "\n",
    "bones = []\n",
    "max_indx = 0\n",
    "# Explore the \"Bone\" elements\n",
    "for bone in root.findall(\".//Bone\"):\n",
    "    #print(\"Bone:\")\n",
    "    for index in bone.findall(\".//Index\"):\n",
    "        low = index.get(\"Low\")\n",
    "        high = index.get(\"High\")\n",
    "        #print(f\"  Index: Low={low}, High={high}\")\n",
    "        bones.append((int(low)-1,int(high)-1))\n",
    "        if int(low) > max_indx or int(high) > max_indx:\n",
    "            max_indx = max(int(low),int(high))\n",
    "\n",
    "markers = []\n",
    "# Explore the \"Trajectory\" elements\n",
    "for trajectory in root.findall(\".//Trajectory\"):\n",
    "    name = trajectory.find(\".//Name\").text\n",
    "    #print(f\"Trajectory: Name={name}\")\n",
    "    markers.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullPosTableY = fullMarkersTable.iloc[:,3::3]\n",
    "fullPosTableZ = fullMarkersTable.iloc[:,4::3]\n",
    "fullPosTableX = fullMarkersTable.iloc[:,5::3]\n",
    "\n",
    "fullPosTableX = fullPosTableX.rename(columns=dict(zip(list(fullPosTableX),[name.replace('Z','X').replace('Y','X') for name in list(fullPosTableX)])))\n",
    "fullPosTableY = fullPosTableY.rename(columns=dict(zip(list(fullPosTableY),[name.replace('Z','Y').replace('X','Y') for name in list(fullPosTableY)])))\n",
    "fullPosTableZ = fullPosTableZ.rename(columns=dict(zip(list(fullPosTableZ),[name.replace('X','Z').replace('Y','Z') for name in list(fullPosTableZ)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: <object object at 0x7fe0a6b816d0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3233/3347424033.py:38: MatplotlibDeprecationWarning: The w_xaxis attribute was deprecated in Matplotlib 3.1 and will be removed in 3.8. Use xaxis instead.\n",
      "  ax.w_xaxis.pane.fill = False\n",
      "/tmp/ipykernel_3233/3347424033.py:39: MatplotlibDeprecationWarning: The w_yaxis attribute was deprecated in Matplotlib 3.1 and will be removed in 3.8. Use yaxis instead.\n",
      "  ax.w_yaxis.pane.fill = False\n",
      "/tmp/ipykernel_3233/3347424033.py:40: MatplotlibDeprecationWarning: The w_zaxis attribute was deprecated in Matplotlib 3.1 and will be removed in 3.8. Use zaxis instead.\n",
      "  ax.w_zaxis.pane.fill = True\n",
      "/tmp/ipykernel_3233/3347424033.py:41: MatplotlibDeprecationWarning: The w_zaxis attribute was deprecated in Matplotlib 3.1 and will be removed in 3.8. Use zaxis instead.\n",
      "  ax.w_zaxis.pane.set_facecolor((0.92,.92,.92))\n",
      "/tmp/ipykernel_3233/3347424033.py:46: MatplotlibDeprecationWarning: The w_xaxis attribute was deprecated in Matplotlib 3.1 and will be removed in 3.8. Use xaxis instead.\n",
      "  ax.w_xaxis.line.set_visible(False)\n",
      "/tmp/ipykernel_3233/3347424033.py:47: MatplotlibDeprecationWarning: The w_yaxis attribute was deprecated in Matplotlib 3.1 and will be removed in 3.8. Use yaxis instead.\n",
      "  ax.w_yaxis.line.set_visible(True)\n",
      "/tmp/ipykernel_3233/3347424033.py:48: MatplotlibDeprecationWarning: The w_zaxis attribute was deprecated in Matplotlib 3.1 and will be removed in 3.8. Use zaxis instead.\n",
      "  ax.w_zaxis.line.set_visible(False)\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib\n",
    "from matplotlib.widgets import Slider\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "edges = np.array(bones)\n",
    "adjacencyMatrix = np.zeros((max_indx,max_indx),dtype=bool)\n",
    "adjacencyMatrix[edges[:,0],edges[:,1]] = True\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig = plt.figure(figsize=(960/100, 720/100), dpi=100)\n",
    "\n",
    "# Add a 3D subplot with the specified position and size\n",
    "ax = fig.add_axes([-0.05, -0.4, 1, 1.7], projection='3d')\n",
    "ax.view_init(elev=10, azim=180)\n",
    "\n",
    "\n",
    "minMax = np.zeros((2,3))\n",
    "minMax[0,:] = [fullPosTableX.values.min(),fullPosTableY.values.min(),fullPosTableZ.values.min()]\n",
    "minMax[1,:] = [fullPosTableX.values.max(),fullPosTableY.values.max(),fullPosTableZ.values.max()]\n",
    "\n",
    "# Set appropriate axis limits\n",
    "ax.set_xlim([minMax[0,0],minMax[1,0]])\n",
    "ax.set_ylim([minMax[0,1],minMax[1,1]])\n",
    "ax.set_zlim([minMax[0,2],minMax[1,2]])\n",
    "\n",
    "# Set the window title\n",
    "fig.canvas.manager.window.title(\"3D Movement\\t(Scroll with mouse wheel)\")\n",
    "\n",
    "# Set the initial time index\n",
    "time_index = 1000\n",
    "colors = ['red', 'blue', 'green', 'purple', 'orange', 'yellow', 'cyan']\n",
    "plt.rcParams['grid.color'] = 'white'\n",
    "ax.tick_params(axis='both', colors='w')\n",
    "# Remove box faces except the ground\n",
    "ax.w_xaxis.pane.fill = False\n",
    "ax.w_yaxis.pane.fill = False\n",
    "ax.w_zaxis.pane.fill = True\n",
    "ax.w_zaxis.pane.set_facecolor((0.92,.92,.92))\n",
    "ax.xaxis.pane.set_edgecolor('w')\n",
    "ax.yaxis.pane.set_edgecolor('w')\n",
    "ax.zaxis.pane.set_edgecolor((0,0,0))\n",
    "# Hide axis spines and ticks\n",
    "ax.w_xaxis.line.set_visible(False)\n",
    "ax.w_yaxis.line.set_visible(True)\n",
    "ax.w_zaxis.line.set_visible(False) \n",
    "\n",
    "# Function to update the plot based on the slider value\n",
    "def update_plot(val):\n",
    "    ax.cla()  # Clear the previous plot\n",
    "    \n",
    "    # Filter the data based on the current time index\n",
    "    filteredX = fullPosTableX.iloc[val]\n",
    "    filteredY = fullPosTableY.iloc[val]\n",
    "    filteredZ = fullPosTableZ.iloc[val]\n",
    "    \n",
    "    ax.scatter(filteredX,filteredY,filteredZ,s=10)\n",
    "\n",
    "    # Add edges based on the weight matrix\n",
    "    for i in range(max_indx):\n",
    "        for j in range(i + 1, max_indx):\n",
    "            if adjacencyMatrix[i,j]:\n",
    "                ax.plot([filteredX[i], filteredX[j]],\n",
    "                        [filteredY[i], filteredY[j]],\n",
    "                        [filteredZ[i], filteredZ[j]],\n",
    "                        color='k', linestyle='-', linewidth=0.7)\n",
    "\n",
    "    ax.set_xlim([0,1])#minMax[0,0],minMax[1,0]])\n",
    "    ax.set_ylim([0,1])#minMax[0,1],minMax[1,1]])\n",
    "    ax.set_zlim([minMax[0,2],minMax[1,2]])\n",
    "    \n",
    "    #ax.set_xlabel('X', fontsize=12)\n",
    "    #ax.set_ylabel('Y', fontsize=12)\n",
    "\n",
    "    #ax.set_zlabel('Z', fontsize=12)\n",
    "    #ax.set_title(\"Movement \"+str(picked))\n",
    "    #ax.grid(axis=['x','y'])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_zticks([])\n",
    "    #ax.set_xticklabels([])\n",
    "    #ax.set_yticklabels([])\n",
    "    #ax.set_zticklabels([])\n",
    "    fig.canvas.draw_idle()\n",
    "    \n",
    "# Create a slider widget\n",
    "slider_ax = plt.axes([0.2, 0.03, 0.6, 0.03])\n",
    "maxValue = fullPosTableX.shape[0]-1\n",
    "slider = Slider(slider_ax, 'TimeIndex:', 0, maxValue, valinit=time_index, valstep=1)\n",
    "\n",
    "\n",
    "# Define a function to update the slider value with the mouse wheel\n",
    "def on_scroll(event):\n",
    "    if event.button == 'down':\n",
    "        if slider.val + slider.valstep <= maxValue:\n",
    "            slider.set_val(slider.val + slider.valstep)\n",
    "    elif event.button == 'up':\n",
    "        if slider.val - slider.valstep >= 0:\n",
    "            slider.set_val(slider.val - slider.valstep)\n",
    "        \n",
    "\n",
    "# Connect the mouse wheel event to the function\n",
    "fig.canvas.mpl_connect('scroll_event', on_scroll)\n",
    "\n",
    "\n",
    "# Register the update_plot function with the slider widget\n",
    "slider.on_changed(update_plot)\n",
    "\n",
    "# Initial plot\n",
    "update_plot(time_index)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gagg/Desktop/Thesis/OoM-Thesis/docs/presentation/resources/2016-05-26_t_006.mp4\n",
      "50 3201.0\n",
      "6195.0 960.0 540.0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Open the video file\n",
    "video_path = '/'.join(os.getcwd().split('/')[:-2]+['docs','presentation','resources','_'.join([folder,trial])+'.mp4'])\n",
    "print(video_path)\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get the frames per second (FPS)\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "print(fps, cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "ret, prev_frame = cap.read()\n",
    "ret= not os.path.isfile(video_path[:-4]+'_'+str(fps * 2)+'fps.mp4')\n",
    "num_frames = 0\n",
    "if ret:\n",
    "    output = cv2.VideoWriter(video_path[:-4]+'_'+str(fps * 2)+'fps.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps * 2, (int(cap.get(3)), int(cap.get(4))))\n",
    "    while True:\n",
    "        if num_frames < len(fullMarkersTable):\n",
    "            output.write(prev_frame)\n",
    "            num_frames += 1\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        averaged_frame = cv2.addWeighted(prev_frame, 0.5, frame, 0.5, 0)\n",
    "        if num_frames < len(fullMarkersTable):\n",
    "            output.write(averaged_frame)\n",
    "            num_frames += 1\n",
    "        else: break\n",
    "        prev_frame = frame\n",
    "    output.release()\n",
    "else: \n",
    "    vidcap = cv2.VideoCapture(video_path[:-4]+'_'+str(fps * 2)+'fps_540p.mp4')\n",
    "    print(vidcap.get(cv2.CAP_PROP_FRAME_COUNT), vidcap.get(3),vidcap.get(4))\n",
    "print(num_frames)\n",
    "\n",
    "# Release the video file\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3233/1188419287.py:29: MatplotlibDeprecationWarning: The w_xaxis attribute was deprecated in Matplotlib 3.1 and will be removed in 3.8. Use xaxis instead.\n",
      "  ax_full.w_xaxis.pane.fill = False\n",
      "/tmp/ipykernel_3233/1188419287.py:30: MatplotlibDeprecationWarning: The w_yaxis attribute was deprecated in Matplotlib 3.1 and will be removed in 3.8. Use yaxis instead.\n",
      "  ax_full.w_yaxis.pane.fill = False\n",
      "/tmp/ipykernel_3233/1188419287.py:31: MatplotlibDeprecationWarning: The w_zaxis attribute was deprecated in Matplotlib 3.1 and will be removed in 3.8. Use zaxis instead.\n",
      "  ax_full.w_zaxis.pane.fill = True\n",
      "/tmp/ipykernel_3233/1188419287.py:32: MatplotlibDeprecationWarning: The w_zaxis attribute was deprecated in Matplotlib 3.1 and will be removed in 3.8. Use zaxis instead.\n",
      "  ax_full.w_zaxis.pane.set_facecolor((0.92,.92,.92))\n",
      "/tmp/ipykernel_3233/1188419287.py:37: MatplotlibDeprecationWarning: The w_xaxis attribute was deprecated in Matplotlib 3.1 and will be removed in 3.8. Use xaxis instead.\n",
      "  ax_full.w_xaxis.line.set_visible(False)\n",
      "/tmp/ipykernel_3233/1188419287.py:38: MatplotlibDeprecationWarning: The w_yaxis attribute was deprecated in Matplotlib 3.1 and will be removed in 3.8. Use yaxis instead.\n",
      "  ax_full.w_yaxis.line.set_visible(True)\n",
      "/tmp/ipykernel_3233/1188419287.py:39: MatplotlibDeprecationWarning: The w_zaxis attribute was deprecated in Matplotlib 3.1 and will be removed in 3.8. Use zaxis instead.\n",
      "  ax_full.w_zaxis.line.set_visible(False)\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib\n",
    "\n",
    "edges = np.array(bones)\n",
    "fullAdjacencyMatrix = np.zeros((max_indx,max_indx),dtype=bool)\n",
    "fullAdjacencyMatrix[edges[:,0],edges[:,1]] = True\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig_full = plt.figure(figsize=(960/100, 540/100), dpi=100)\n",
    "\n",
    "# Add a 3D subplot with the specified position and size\n",
    "ax_full = fig_full.add_axes([-0.3, -0.2, 1.6, 1.6], projection='3d')\n",
    "ax_full.view_init(elev=10, azim=180)\n",
    "\n",
    "\n",
    "fullMinMax = np.zeros((2,3))\n",
    "fullMinMax[0,:] = [fullPosTableX.values.min(),fullPosTableY.values.min(),fullPosTableZ.values.min()]\n",
    "fullMinMax[1,:] = [fullPosTableX.values.max(),fullPosTableY.values.max(),fullPosTableZ.values.max()]\n",
    "\n",
    "# Set appropriate axis limits\n",
    "ax_full.set_xlim([fullMinMax[0,0],fullMinMax[1,0]])\n",
    "ax_full.set_ylim([fullMinMax[0,1],fullMinMax[1,1]])\n",
    "ax_full.set_zlim([fullMinMax[0,2],fullMinMax[1,2]])\n",
    "\n",
    "\n",
    "plt.rcParams['grid.color'] = 'white'\n",
    "ax_full.tick_params(axis='both', colors='w')\n",
    "# Remove box faces except the ground\n",
    "ax_full.w_xaxis.pane.fill = False\n",
    "ax_full.w_yaxis.pane.fill = False\n",
    "ax_full.w_zaxis.pane.fill = True\n",
    "ax_full.w_zaxis.pane.set_facecolor((0.92,.92,.92))\n",
    "ax_full.xaxis.pane.set_edgecolor('w')\n",
    "ax_full.yaxis.pane.set_edgecolor('w')\n",
    "ax_full.zaxis.pane.set_edgecolor((0,0,0))\n",
    "# Hide axis spines and ticks\n",
    "ax_full.w_xaxis.line.set_visible(False)\n",
    "ax_full.w_yaxis.line.set_visible(True)\n",
    "ax_full.w_zaxis.line.set_visible(False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducedPosTableY = reducedMarkersTable.iloc[:,::3]\n",
    "reducedPosTableZ = reducedMarkersTable.iloc[:,1::3]\n",
    "reducedPosTableX = reducedMarkersTable.iloc[:,2::3]\n",
    "\n",
    "reducedPosTableX = reducedPosTableX.rename(columns=dict(zip(list(reducedPosTableX),[name.replace('Z','X').replace('Y','X') for name in list(reducedPosTableX)])))\n",
    "reducedPosTableY = reducedPosTableY.rename(columns=dict(zip(list(reducedPosTableY),[name.replace('Z','Y').replace('X','Y') for name in list(reducedPosTableY)])))\n",
    "reducedPosTableZ = reducedPosTableZ.rename(columns=dict(zip(list(reducedPosTableZ),[name.replace('X','Z').replace('Y','Z') for name in list(reducedPosTableZ)])))\n",
    "\n",
    "jointsFrom = [1, 3, 5, 7, 2, 4, 6, 9, 8,10,11,13,15,17,12,14,16,19,18]\n",
    "jointsTo =   [3, 5, 7, 8, 4, 6, 9, 8,10,18,13,15,17,18,14,16,19,18,20]\n",
    "jointsFrom = list(map(lambda x: x-1,jointsFrom))\n",
    "jointsTo = list(map(lambda x: x-1,jointsTo))\n",
    "edges = np.array(list(zip(jointsFrom,jointsTo))+list(zip(jointsTo,jointsFrom)))\n",
    "adjacencyMatrix = np.zeros((20,20),dtype=bool)\n",
    "adjacencyMatrix[edges[:,0],edges[:,1]] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3233/958718550.py:21: MatplotlibDeprecationWarning: The w_xaxis attribute was deprecated in Matplotlib 3.1 and will be removed in 3.8. Use xaxis instead.\n",
      "  ax_reduced.w_xaxis.pane.fill = False\n",
      "/tmp/ipykernel_3233/958718550.py:22: MatplotlibDeprecationWarning: The w_yaxis attribute was deprecated in Matplotlib 3.1 and will be removed in 3.8. Use yaxis instead.\n",
      "  ax_reduced.w_yaxis.pane.fill = False\n",
      "/tmp/ipykernel_3233/958718550.py:23: MatplotlibDeprecationWarning: The w_zaxis attribute was deprecated in Matplotlib 3.1 and will be removed in 3.8. Use zaxis instead.\n",
      "  ax_reduced.w_zaxis.pane.fill = True\n",
      "/tmp/ipykernel_3233/958718550.py:24: MatplotlibDeprecationWarning: The w_zaxis attribute was deprecated in Matplotlib 3.1 and will be removed in 3.8. Use zaxis instead.\n",
      "  ax_reduced.w_zaxis.pane.set_facecolor((0.92,.92,.92))\n",
      "/tmp/ipykernel_3233/958718550.py:29: MatplotlibDeprecationWarning: The w_xaxis attribute was deprecated in Matplotlib 3.1 and will be removed in 3.8. Use xaxis instead.\n",
      "  ax_reduced.w_xaxis.line.set_visible(False)\n",
      "/tmp/ipykernel_3233/958718550.py:30: MatplotlibDeprecationWarning: The w_yaxis attribute was deprecated in Matplotlib 3.1 and will be removed in 3.8. Use yaxis instead.\n",
      "  ax_reduced.w_yaxis.line.set_visible(True)\n",
      "/tmp/ipykernel_3233/958718550.py:31: MatplotlibDeprecationWarning: The w_zaxis attribute was deprecated in Matplotlib 3.1 and will be removed in 3.8. Use zaxis instead.\n",
      "  ax_reduced.w_zaxis.line.set_visible(False)\n"
     ]
    }
   ],
   "source": [
    "fig_reduced = plt.figure(figsize=(960/100, 540/100), dpi=100)\n",
    "\n",
    "# Add a 3D subplot with the specified position and size\n",
    "ax_reduced = fig_reduced.add_axes([-0.3, -0.2, 1.6, 1.6], projection='3d')\n",
    "ax_reduced.view_init(elev=10, azim=180)\n",
    "\n",
    "\n",
    "reducedMinMax = np.zeros((2,3))\n",
    "reducedMinMax[0,:] = [reducedPosTableX.values.min(),reducedPosTableY.values.min(),reducedPosTableZ.values.min()]\n",
    "reducedMinMax[1,:] = [reducedPosTableX.values.max(),reducedPosTableY.values.max(),reducedPosTableZ.values.max()]\n",
    "\n",
    "# Set appropriate axis limits\n",
    "ax_reduced.set_xlim([reducedMinMax[0,0],reducedMinMax[1,0]])\n",
    "ax_reduced.set_ylim([reducedMinMax[0,1],reducedMinMax[1,1]])\n",
    "ax_reduced.set_zlim([reducedMinMax[0,2],reducedMinMax[1,2]])\n",
    "\n",
    "\n",
    "plt.rcParams['grid.color'] = 'white'\n",
    "ax_reduced.tick_params(axis='both', colors='w')\n",
    "# Remove box faces except the ground\n",
    "ax_reduced.w_xaxis.pane.fill = False\n",
    "ax_reduced.w_yaxis.pane.fill = False\n",
    "ax_reduced.w_zaxis.pane.fill = True\n",
    "ax_reduced.w_zaxis.pane.set_facecolor((0.92,.92,.92))\n",
    "ax_reduced.xaxis.pane.set_edgecolor('w')\n",
    "ax_reduced.yaxis.pane.set_edgecolor('w')\n",
    "ax_reduced.zaxis.pane.set_edgecolor((0,0,0))\n",
    "# Hide axis spines and ticks\n",
    "ax_reduced.w_xaxis.line.set_visible(False)\n",
    "ax_reduced.w_yaxis.line.set_visible(True)\n",
    "ax_reduced.w_zaxis.line.set_visible(False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to update the plot based on the slider value\n",
    "def get_frame_full_skeleton(fig, ax, val):\n",
    "    ax.cla()  # Clear the previous plot\n",
    "    \n",
    "    # Filter the data based on the current time index\n",
    "    filteredX = fullPosTableX.iloc[val]\n",
    "    filteredY = fullPosTableY.iloc[val]\n",
    "    filteredZ = fullPosTableZ.iloc[val]\n",
    "    \n",
    "    ax.scatter(filteredX,filteredY,filteredZ,s=10)\n",
    "\n",
    "    # Add edges based on the weight matrix\n",
    "    for i in range(len(fullAdjacencyMatrix)):\n",
    "        for j in range(i + 1, len(fullAdjacencyMatrix)):\n",
    "            if fullAdjacencyMatrix[i,j]:\n",
    "                ax.plot([filteredX[i], filteredX[j]],\n",
    "                        [filteredY[i], filteredY[j]],\n",
    "                        [filteredZ[i], filteredZ[j]],\n",
    "                        color='k', linestyle='-', linewidth=1)\n",
    "\n",
    "    ax.set_xlim([0,1])\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.set_zlim([fullMinMax[0,2],fullMinMax[1,2]])\n",
    "\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_zticks([])\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    buf = fig.canvas.tostring_rgb()\n",
    "    ncols, nrows = fig.canvas.get_width_height()\n",
    "    frame = np.frombuffer(buf, dtype=np.uint8).reshape(nrows, ncols, 3)\n",
    "\n",
    "    return frame\n",
    "\n",
    "def get_frame_reduced_skeleton(fig, ax, val):\n",
    "    ax.cla()  # Clear the previous plot\n",
    "    \n",
    "    # Filter the data based on the current time index\n",
    "    filteredX = reducedPosTableX.iloc[val]\n",
    "    filteredY = reducedPosTableY.iloc[val]\n",
    "    filteredZ = reducedPosTableZ.iloc[val]\n",
    "    \n",
    "    ax.scatter(filteredX,filteredY,filteredZ,s=50)\n",
    "\n",
    "    # Add edges based on the weight matrix\n",
    "    for i in range(len(adjacencyMatrix)):\n",
    "        for j in range(i + 1, len(adjacencyMatrix)):\n",
    "            if adjacencyMatrix[i,j]:\n",
    "                ax.plot([filteredX[i], filteredX[j]],\n",
    "                        [filteredY[i], filteredY[j]],\n",
    "                        [filteredZ[i], filteredZ[j]],\n",
    "                        color='k', linestyle='-', linewidth=1.5)\n",
    "\n",
    "    ax.set_xlim([0,1])\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.set_zlim([reducedMinMax[0,2],reducedMinMax[1,2]])\n",
    "\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_zticks([])\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    buf = fig.canvas.tostring_rgb()\n",
    "    ncols, nrows = fig.canvas.get_width_height()\n",
    "    frame = np.frombuffer(buf, dtype=np.uint8).reshape(nrows, ncols, 3)\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating video of the VidCap / 64 Markers Skeleton / 20 Markers Skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd00bb1aa814fc08ada22403f1be40c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving video: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Create a VideoWriter object in OpenCV\n",
    "full_hd = (1920,1080)\n",
    "record = not os.path.isfile(video_path[:-4]+'_'+str(fps * 2)+'fps_plus_skeleton.mp4')\n",
    "if record:\n",
    "    out = cv2.VideoWriter(video_path[:-4]+'_'+str(fps * 2)+'fps_plus_skeleton.mp4', \n",
    "                          cv2.VideoWriter_fourcc(*'mp4v'), \n",
    "                          fps*2, \n",
    "                          full_hd)  # Adjust the filename, codec, frame rate, and frame size\n",
    "\n",
    "vidcap = cv2.VideoCapture(video_path[:-4]+'_'+str(fps * 2)+'fps_540p.mp4')\n",
    "#print(vidcap.get(cv2.CAP_PROP_FRAME_COUNT),len(fullMarkersTable))\n",
    "filler_size = tuple(map(int,(vidcap.get(4),(full_hd[0]-vidcap.get(3))/2,3)))\n",
    "filler = np.zeros(filler_size,dtype=np.uint8)+255\n",
    "# Loop to update the plot and write frames to the video\n",
    "for val in tqdm(range(len(fullMarkersTable)*(int(record)*2-1)),'Saving video',miniters=20):  # Replace total_frames with the actual number of frames\n",
    "    ret, video_frame = vidcap.read()\n",
    "    if not ret:\n",
    "        break    \n",
    "    # Draw an empty blue rectangle\n",
    "    video_frame = cv2.rectangle(video_frame, (10, 10), (int(vidcap.get(3)-11), int(vidcap.get(4)-11)), (0, 0, 255), 2)\n",
    "    video_frame = cv2.rectangle(video_frame, (0, 0), (int(vidcap.get(3)-2), int(vidcap.get(4)-2)), (127, 127, 127), 3)\n",
    "    frame_full_skeleton = cv2.cvtColor(get_frame_full_skeleton(fig_full, ax_full, val), cv2.COLOR_RGB2BGR)\n",
    "    frame_reduced_skeleton = cv2.cvtColor(get_frame_reduced_skeleton(fig_reduced, ax_reduced, val), cv2.COLOR_RGB2BGR)\n",
    "    out.write(np.vstack((np.hstack((filler,video_frame,filler)), np.hstack((frame_full_skeleton,frame_reduced_skeleton)))))\n",
    "\n",
    "\n",
    "# Release the VideoWriter and close the OpenCV window (if used)\n",
    "if record:\n",
    "    out.release()\n",
    "vidcap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the version VidCap / 20 Markers clustered / 20 Markers Clustered stabilized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducedPosTableY = reducedMarkersTable.iloc[:,::3]\n",
    "reducedPosTableZ = reducedMarkersTable.iloc[:,1::3]\n",
    "reducedPosTableX = reducedMarkersTable.iloc[:,2::3]\n",
    "\n",
    "reducedPosTableX = reducedPosTableX.rename(columns=dict(zip(list(reducedPosTableX),[name.replace('Z','X').replace('Y','X') for name in list(reducedPosTableX)])))\n",
    "reducedPosTableY = reducedPosTableY.rename(columns=dict(zip(list(reducedPosTableY),[name.replace('Z','Y').replace('X','Y') for name in list(reducedPosTableY)])))\n",
    "reducedPosTableZ = reducedPosTableZ.rename(columns=dict(zip(list(reducedPosTableZ),[name.replace('X','Z').replace('Y','Z') for name in list(reducedPosTableZ)])))\n",
    "\n",
    "jointsFrom = [1, 3, 5, 7, 2, 4, 6, 9, 8,10,11,13,15,17,12,14,16,19,18]\n",
    "jointsTo =   [3, 5, 7, 8, 4, 6, 9, 8,10,18,13,15,17,18,14,16,19,18,20]\n",
    "jointsFrom = list(map(lambda x: x-1,jointsFrom))\n",
    "jointsTo = list(map(lambda x: x-1,jointsTo))\n",
    "edges = np.array(list(zip(jointsFrom,jointsTo))+list(zip(jointsTo,jointsFrom)))\n",
    "adjacencyMatrix = np.zeros((20,20),dtype=bool)\n",
    "adjacencyMatrix[edges[:,0],edges[:,1]] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3233/253775057.py:22: MatplotlibDeprecationWarning: The w_xaxis attribute was deprecated in Matplotlib 3.1 and will be removed in 3.8. Use xaxis instead.\n",
      "  ax_reduced.w_xaxis.pane.fill = False\n",
      "/tmp/ipykernel_3233/253775057.py:23: MatplotlibDeprecationWarning: The w_yaxis attribute was deprecated in Matplotlib 3.1 and will be removed in 3.8. Use yaxis instead.\n",
      "  ax_reduced.w_yaxis.pane.fill = False\n",
      "/tmp/ipykernel_3233/253775057.py:24: MatplotlibDeprecationWarning: The w_zaxis attribute was deprecated in Matplotlib 3.1 and will be removed in 3.8. Use zaxis instead.\n",
      "  ax_reduced.w_zaxis.pane.fill = True\n",
      "/tmp/ipykernel_3233/253775057.py:25: MatplotlibDeprecationWarning: The w_zaxis attribute was deprecated in Matplotlib 3.1 and will be removed in 3.8. Use zaxis instead.\n",
      "  ax_reduced.w_zaxis.pane.set_facecolor((0.92,.92,.92))\n",
      "/tmp/ipykernel_3233/253775057.py:30: MatplotlibDeprecationWarning: The w_xaxis attribute was deprecated in Matplotlib 3.1 and will be removed in 3.8. Use xaxis instead.\n",
      "  ax_reduced.w_xaxis.line.set_visible(False)\n",
      "/tmp/ipykernel_3233/253775057.py:31: MatplotlibDeprecationWarning: The w_yaxis attribute was deprecated in Matplotlib 3.1 and will be removed in 3.8. Use yaxis instead.\n",
      "  ax_reduced.w_yaxis.line.set_visible(True)\n",
      "/tmp/ipykernel_3233/253775057.py:32: MatplotlibDeprecationWarning: The w_zaxis attribute was deprecated in Matplotlib 3.1 and will be removed in 3.8. Use zaxis instead.\n",
      "  ax_reduced.w_zaxis.line.set_visible(False)\n"
     ]
    }
   ],
   "source": [
    "plt.close('all')\n",
    "fig_reduced = plt.figure(figsize=(960/100, 720/100), dpi=100)\n",
    "\n",
    "# Add a 3D subplot with the specified position and size\n",
    "ax_reduced = fig_reduced.add_axes([-0.3, -0.2, 1.6, 1.6], projection='3d')\n",
    "ax_reduced.view_init(elev=10, azim=180)\n",
    "\n",
    "\n",
    "reducedMinMax = np.zeros((2,3))\n",
    "reducedMinMax[0,:] = [reducedPosTableX.values.min(),reducedPosTableY.values.min(),reducedPosTableZ.values.min()]\n",
    "reducedMinMax[1,:] = [reducedPosTableX.values.max(),reducedPosTableY.values.max(),reducedPosTableZ.values.max()]\n",
    "\n",
    "# Set appropriate axis limits\n",
    "ax_reduced.set_xlim([reducedMinMax[0,0],reducedMinMax[1,0]])\n",
    "ax_reduced.set_ylim([reducedMinMax[0,1],reducedMinMax[1,1]])\n",
    "ax_reduced.set_zlim([reducedMinMax[0,2],reducedMinMax[1,2]])\n",
    "\n",
    "\n",
    "plt.rcParams['grid.color'] = 'white'\n",
    "ax_reduced.tick_params(axis='both', colors='w')\n",
    "# Remove box faces except the ground\n",
    "ax_reduced.w_xaxis.pane.fill = False\n",
    "ax_reduced.w_yaxis.pane.fill = False\n",
    "ax_reduced.w_zaxis.pane.fill = True\n",
    "ax_reduced.w_zaxis.pane.set_facecolor((0.92,.92,.92))\n",
    "ax_reduced.xaxis.pane.set_edgecolor('w')\n",
    "ax_reduced.yaxis.pane.set_edgecolor('w')\n",
    "ax_reduced.zaxis.pane.set_edgecolor((0,0,0))\n",
    "# Hide axis spines and ticks\n",
    "ax_reduced.w_xaxis.line.set_visible(False)\n",
    "ax_reduced.w_yaxis.line.set_visible(True)\n",
    "ax_reduced.w_zaxis.line.set_visible(False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "color_pool = ['#e31a1c', '#1f78b4', '#33a02c', '#ff7f00', '#6a3d9a', '#b15928']\n",
    "\n",
    "def get_frame_reduced_skeleton_clustered(fig, ax, val, clusters,subtitle):\n",
    "    ax.cla()  # Clear the previous plot\n",
    "    \n",
    "    # Filter the data based on the current time index\n",
    "    filteredX = reducedPosTableX.iloc[val]\n",
    "    filteredY = reducedPosTableY.iloc[val]\n",
    "    filteredZ = reducedPosTableZ.iloc[val]\n",
    "    \n",
    "    ax.scatter(filteredX,filteredY,filteredZ,s=100,c=[color_pool[i] for i in clusters])\n",
    "\n",
    "    # Add edges based on the weight matrix\n",
    "    for i in range(len(adjacencyMatrix)):\n",
    "        for j in range(i + 1, len(adjacencyMatrix)):\n",
    "            if adjacencyMatrix[i,j]:\n",
    "                ax.plot([filteredX[i], filteredX[j]],\n",
    "                        [filteredY[i], filteredY[j]],\n",
    "                        [filteredZ[i], filteredZ[j]],\n",
    "                        color='k', linestyle='-', linewidth=1.5)\n",
    "\n",
    "    ax.set_xlim([0,1])\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.set_zlim([reducedMinMax[0,2],reducedMinMax[1,2]])\n",
    "\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_zticks([])\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    buf = fig.canvas.tostring_rgb()\n",
    "    ncols, nrows = fig.canvas.get_width_height()\n",
    "    frame = np.frombuffer(buf, dtype=np.uint8).reshape(nrows, ncols, 3)\n",
    "    frame = cv2.putText(frame, subtitle, ((frame.shape[1]-cv2.getTextSize(subtitle, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)[0][0])//2, frame.shape[0] - 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clustering import table_to_list_xyz_tables, group_table_by_joints, compute_derivatives, xyz_tables_to_xyz_columns, smoothing, joints_array_to_xyz_columns\n",
    "import re\n",
    "\n",
    "# Calculate angular momentum\n",
    "if not os.path.isfile('_angmom.csv'): \n",
    "    dt = ((float(endSec)-float(startSec)) / len(reducedMarkersTable))\n",
    "    centerOfMassPosTable = pd.concat([table.apply(lambda row: row.sum()/20,axis=1) for table in table_to_list_xyz_tables(reducedMarkersTable)],axis=1)\n",
    "    relativePosTable = group_table_by_joints(xyz_tables_to_xyz_columns([posTableAxis.subtract(centerOfMassPosTable.iloc[:,j],axis=0) for j,posTableAxis in enumerate(table_to_list_xyz_tables(reducedMarkersTable))]))\n",
    "    centerOfMassVelocityTable = compute_derivatives(centerOfMassPosTable,dt,smooth=False)\n",
    "    relativeVelocityTable = group_table_by_joints(xyz_tables_to_xyz_columns([velocityTableAxis.subtract(centerOfMassVelocityTable.iloc[:,j],axis=0) for j,velocityTableAxis in enumerate(table_to_list_xyz_tables(compute_derivatives(reducedMarkersTable,dt)))]))\n",
    "    angularMomentumTable = relativePosTable\n",
    "    for i in range(len(relativePosTable)):\n",
    "        for j in range(len(relativePosTable.columns)):\n",
    "            angularMomentumTable.iloc[i,j][:] = np.cross(relativePosTable.iloc[i,j],relativeVelocityTable.iloc[i,j])\n",
    "    angularMomentumTable = group_table_by_joints(smoothing(joints_array_to_xyz_columns(angularMomentumTable)))\n",
    "    # Soooo long to recompute each time... better save a file\n",
    "    angularMomentumTable.to_csv('_angmom.csv', index=False)\n",
    "else:\n",
    "    angularMomentumTable = pd.read_csv('_angmom.csv')\n",
    "    angularMomentumTable = angularMomentumTable.applymap(lambda cell: np.array(eval(re.sub(r'(?<=[\\d-])\\s{1,}(?=[\\d-])', ', ',cell))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e412f86332f148138eb7280b89d06d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving video: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "from clustering import *\n",
    "\n",
    "# Create a VideoWriter object in OpenCV\n",
    "full_hd = (1920,1080)\n",
    "record = not os.path.isfile(video_path[:-4]+'_'+str(fps * 2)+'fps_clustered.mp4')\n",
    "if record:\n",
    "    out = cv2.VideoWriter(video_path[:-4]+'_'+str(fps * 2)+'fps_clustered.mp4', \n",
    "                          cv2.VideoWriter_fourcc(*'mp4v'), \n",
    "                          fps*2, \n",
    "                          full_hd)  # Adjust the filename, codec, frame rate, and frame size\n",
    "\n",
    "vidcap = cv2.VideoCapture(video_path[:-4]+'_'+str(fps * 2)+'fps_360p.mp4')\n",
    "filler_size = tuple(map(int,(vidcap.get(4),(full_hd[0]-vidcap.get(3))/2,3)))\n",
    "filler = np.zeros(filler_size,dtype=np.uint8)+255\n",
    "weightMatrix = calculate_weight_matrix(angularMomentumTable.iloc[0],adjacencyMatrix)\n",
    "stabilized_labels = shi_malik_spectral_clustering_matlab_version(weightMatrix)\n",
    "# Loop to update the plot and write frames to the video\n",
    "for val in tqdm(range(len(fullMarkersTable)*(int(record)*2-1)),'Saving video',miniters=20):  # Replace total_frames with the actual number of frames\n",
    "    ret, video_frame = vidcap.read()\n",
    "    if not ret:\n",
    "        break    \n",
    "    weightMatrix = calculate_weight_matrix(angularMomentumTable.iloc[val],adjacencyMatrix)\n",
    "    predicted_labels = shi_malik_spectral_clustering_matlab_version(weightMatrix)\n",
    "    stabilized_labels = compute_minimum_weight_cluster(stabilized_labels,predicted_labels,'MWPM')\n",
    "    # Draw an empty blue rectangle\n",
    "    video_frame = cv2.rectangle(video_frame, (10, 10), (int(vidcap.get(3)-11), int(vidcap.get(4)-11)), (0, 0, 255), 2)\n",
    "    video_frame = cv2.rectangle(video_frame, (0, 0), (int(vidcap.get(3)-2), int(vidcap.get(4)-2)), (127, 127, 127), 3)\n",
    "    frame_clustered = cv2.cvtColor(get_frame_reduced_skeleton_clustered(fig_reduced, ax_reduced, val, predicted_labels,'Simple Clustering'), cv2.COLOR_RGB2BGR)\n",
    "    frame_clustered_stabilized = cv2.cvtColor(get_frame_reduced_skeleton_clustered(fig_reduced, ax_reduced, val, stabilized_labels,'Stabilized Clustering'), cv2.COLOR_RGB2BGR)\n",
    "    out.write(np.vstack((np.hstack((filler,video_frame,filler)), np.hstack((frame_clustered,frame_clustered_stabilized)))))\n",
    "\n",
    "# Release the VideoWriter and close the OpenCV window (if used)\n",
    "if record:\n",
    "    out.release()\n",
    "vidcap.release()\n",
    "#plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "skeleton_graph = nx.from_numpy_array(adjacencyMatrix)\n",
    "leaf_nodes = [node for node in skeleton_graph.nodes() if skeleton_graph.degree(node) == 1]\n",
    "\n",
    "def smooth_clusters_VBase(previous_clusters:list, current_clusters:list,weightMatrix,i:int=0, delay:int=-1):\n",
    "    if delay <= 0 or i % delay != 0:\n",
    "        return previous_clusters\n",
    "\n",
    "    # Compute the frontier of the previous clusters for every cluster\n",
    "    frontier_nodes = { cluster_id: {\n",
    "                        neighbor\n",
    "                        for node in nodes\n",
    "                        for neighbor in skeleton_graph.neighbors(node)\n",
    "                        if neighbor not in nodes\n",
    "                        }\n",
    "                        for cluster_id, nodes in {key: set([i for i, val in enumerate(previous_clusters) if val == key]) \n",
    "                                                    for key in set(previous_clusters)}.items()\n",
    "                     }\n",
    "    \n",
    "    # Update only clusters whose nodes are at the frontier of each cluster\n",
    "    new_clusters = { node: cluster_id\n",
    "                     for cluster_id in set(previous_clusters)\n",
    "                     for node in frontier_nodes[cluster_id]\n",
    "                     if current_clusters[node] == cluster_id }\n",
    "\n",
    "    # Add remaining nodes and update the leaf nodes (to avoid cluster disappearing)\n",
    "    new_clusters.update({ node: current_clusters[node] if not node in new_clusters else cluster_id\n",
    "                            for node, cluster_id in enumerate(previous_clusters) })\n",
    "    \n",
    "    # TODO further improvement may implement the possibility to choose the node from which the\n",
    "    # cluster should fade in, based on the weakest similarity value\n",
    "    return [cluster_id for _,cluster_id in sorted(new_clusters.items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "skeleton_graph = nx.from_numpy_array(adjacencyMatrix)\n",
    "leaf_nodes = [node for node in skeleton_graph.nodes() if skeleton_graph.degree(node) == 1]\n",
    "\n",
    "def smooth_clusters(previous_clusters: list, current_clusters: list, weightMatrix, i: int = 0, delay: int = -1):\n",
    "    if delay <= 0 or i % delay != 0:\n",
    "        return previous_clusters\n",
    "\n",
    "    # Step 1: Create dictionaries for current and previous clusters\n",
    "    current_clusters_dict = {cluster_id: [node for node, cluster in enumerate(current_clusters) if cluster == cluster_id] for cluster_id in set(current_clusters)}\n",
    "    previous_clusters_dict = {cluster_id: [node for node, cluster in enumerate(previous_clusters) if cluster == cluster_id] for cluster_id in set(previous_clusters)}\n",
    "\n",
    "    # Step 2: Subtract current cluster dictionary from previous clusters\n",
    "    changed_clusters = {cluster_id: list(set(current_clusters_dict[cluster_id]) - set(previous_clusters_dict.get(cluster_id, [])) ) for cluster_id in current_clusters_dict}\n",
    "\n",
    "    # Step 3: Sort nodes by increasing weighted degree centrality, grouped by cluster\n",
    "    sorted_nodes_by_centrality = {\n",
    "        cluster_id: [node for node, _ in sorted({node: sum(weightMatrix[node][neighbor] for neighbor in nodes) \n",
    "                                                 for node in nodes}.items(), key=lambda x: x[1], reverse=True)]\n",
    "        for cluster_id, nodes in changed_clusters.items()}\n",
    "\n",
    "    # Step 4: Update one node with the lowest weighted degree centrality for each cluster\n",
    "    out_clusters = {sorted_nodes[0]: cluster_id for cluster_id, sorted_nodes in sorted_nodes_by_centrality.items() if sorted_nodes}\n",
    "\n",
    "\n",
    "    out_clusters.update({ node: cluster_id for node, cluster_id in enumerate(previous_clusters) if not node in out_clusters })\n",
    "\n",
    "    return [cluster_id for _,cluster_id in sorted(out_clusters.items())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec4719c8b0a4d3a8fdf6a0657549f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving video: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "from clustering import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=Warning)\n",
    "\n",
    "# Create a VideoWriter object in OpenCV\n",
    "full_hd = (1920,1080)\n",
    "record = not os.path.isfile(video_path[:-4]+'_'+str(fps * 2)+'fps_clustered_delayed.mp4')\n",
    "if record:\n",
    "    out = cv2.VideoWriter(video_path[:-4]+'_'+str(fps * 2)+'fps_clustered_delayed.mp4', \n",
    "                          cv2.VideoWriter_fourcc(*'mp4v'), \n",
    "                          fps*2, \n",
    "                          full_hd)  # Adjust the filename, codec, frame rate, and frame size\n",
    "\n",
    "vidcap = cv2.VideoCapture(video_path[:-4]+'_'+str(fps * 2)+'fps_360p.mp4')\n",
    "filler_size = tuple(map(int,(vidcap.get(4),(full_hd[0]-vidcap.get(3))/2,3)))\n",
    "filler = np.zeros(filler_size,dtype=np.uint8)+255\n",
    "weightMatrix = calculate_weight_matrix(angularMomentumTable.iloc[0],adjacencyMatrix)\n",
    "stabilized_labels = shi_malik_spectral_clustering_matlab_version(weightMatrix)\n",
    "stabilized_smoothed_labels = stabilized_labels\n",
    "\n",
    "# Loop to update the plot and write frames to the video\n",
    "for val in tqdm(range(len(fullMarkersTable)*(int(record)*2-1)),'Saving video',miniters=20):  # Replace total_frames with the actual number of frames\n",
    "    ret, video_frame = vidcap.read()\n",
    "    if not ret:\n",
    "        break    \n",
    "    weightMatrix = calculate_weight_matrix(angularMomentumTable.iloc[val],adjacencyMatrix)\n",
    "    predicted_labels = shi_malik_spectral_clustering_matlab_version(weightMatrix)\n",
    "    stabilized_labels = compute_minimum_weight_cluster(stabilized_labels,predicted_labels,'MWPM')\n",
    "    stabilized_smoothed_labels = smooth_clusters(stabilized_smoothed_labels,stabilized_labels,weightMatrix,val,fps//4)\n",
    "\n",
    "    # Draw an empty blue rectangle\n",
    "    video_frame = cv2.rectangle(video_frame, (10, 10), (int(vidcap.get(3)-11), int(vidcap.get(4)-11)), (0, 0, 255), 2)\n",
    "    video_frame = cv2.rectangle(video_frame, (0, 0), (int(vidcap.get(3)-2), int(vidcap.get(4)-2)), (127, 127, 127), 3)\n",
    "    frame_clustered = cv2.cvtColor(get_frame_reduced_skeleton_clustered(fig_reduced, ax_reduced, val, stabilized_labels,'Stabilized Clustering'), cv2.COLOR_RGB2BGR)\n",
    "    frame_clustered_stabilized = cv2.cvtColor(get_frame_reduced_skeleton_clustered(fig_reduced, ax_reduced, val, stabilized_smoothed_labels,'Stabilized Smoothed'), cv2.COLOR_RGB2BGR)\n",
    "    #frame_clustered_stabilized = cv2.putText(frame_clustered_stabilized, str(val), (40,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "    out.write(np.vstack((np.hstack((filler,video_frame,filler)), np.hstack((frame_clustered,frame_clustered_stabilized)))))\n",
    "\n",
    "# Release the VideoWriter and close the OpenCV window (if used)\n",
    "if record:\n",
    "    out.release()\n",
    "vidcap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = 704\n",
    "next = 3\n",
    "\n",
    "\n",
    "weightMatrix = calculate_weight_matrix(angularMomentumTable.iloc[val],adjacencyMatrix)\n",
    "standard_labels = shi_malik_spectral_clustering_matlab_version(weightMatrix)\n",
    "plt.imsave('_imgs/pure/pure_t.png',get_frame_reduced_skeleton_clustered(fig_reduced, ax_reduced, val, standard_labels,'t = '+str(val)[0]+'.'+str(val)[1:]))\n",
    "stabilized_smoothed_labels = standard_labels\n",
    "stabilized_labels = standard_labels\n",
    "for i in range(30):\n",
    "    weightMatrix = calculate_weight_matrix(angularMomentumTable.iloc[val],adjacencyMatrix)\n",
    "    standard_labels = shi_malik_spectral_clustering_matlab_version(weightMatrix)\n",
    "    weightMatrix = calculate_weight_matrix(angularMomentumTable.iloc[val+next],adjacencyMatrix)\n",
    "    standard_labels_next = shi_malik_spectral_clustering_matlab_version(weightMatrix)\n",
    "    stabilized_labels = compute_minimum_weight_cluster(stabilized_labels,standard_labels_next,'MWPM')\n",
    "\n",
    "    plt.imsave('_imgs/pure/pure_next_'+str(i)+'.png',get_frame_reduced_skeleton_clustered(fig_reduced, ax_reduced, val+next, standard_labels_next,'t = '+str(val+next)[0]+'.'+str(val+next)[1:]))\n",
    "    #print(standard_labels)\n",
    "    #print(standard_labels_next)\n",
    "    #print(compute_minimum_weight_cluster(standard_labels,standard_labels_next,'MWPM'))\n",
    "    #print(list(stabilized_smoothed_labels))\n",
    "    plt.imsave('_imgs/stabilized/stabilized_next'+str(i)+'.png',get_frame_reduced_skeleton_clustered(fig_reduced, ax_reduced, val+next, stabilized_labels,'t = '+str(val+next)[0]+'.'+str(val+next)[1:]))\n",
    "\n",
    "    stabilized_smoothed_labels = smooth_clusters(stabilized_smoothed_labels,stabilized_labels,weightMatrix,i,2)\n",
    "    plt.imsave('_imgs/smoothed/smoothed_next'+str(i)+'.png',get_frame_reduced_skeleton_clustered(fig_reduced, ax_reduced, val+next, stabilized_smoothed_labels,'t = '+str(val+next)[0]+'.'+str(val+next)[1:]))\n",
    "    val += next\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIF saved as output.gif\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# List of image files\n",
    "image_files = []  # Replace with your file names\n",
    "for i in range(30):\n",
    "    image_files.append('_imgs/smoothed/smoothed_next'+str(i)+'.png')\n",
    "\n",
    "# Create a list to store the images\n",
    "images = []\n",
    "\n",
    "# Load each image and append it to the list\n",
    "for image_file in image_files:\n",
    "    img = Image.open(image_file)\n",
    "    images.append(img)\n",
    "\n",
    "\n",
    "# Set the path for the output GIF\n",
    "output_gif = 'output.gif'\n",
    "\n",
    "# Save the list of images as a GIF\n",
    "images[0].save(output_gif, format='GIF', save_all=True, append_images=images[1:],duration=1,loop=0,quality=20)\n",
    "\n",
    "# Clean up (optional): delete the individual image files if needed\n",
    "#for image_file in image_files:\n",
    "#    os.remove(image_file)\n",
    "\n",
    "print(f'GIF saved as {output_gif}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
